{
  "id": "15432",
  "title": "bouma as bounded map",
  "forum": "General Discussions",
  "tags": [

  ],
  "content": "How many of you think my attempt to ground the term _[bouma](http://web.archive.org/web/20100825012846/http:/typophile.com/wiki/bouma)_ or _bouma shape_ in _bounded map_ has merit? The derivation is based on making the expression _bounded map_ one word and then dropping the _nded_ of _bounded_ and the _p_ of _map_.\n\nThe idea for the derivation was sparked years ago (in a series of early exchanges with Hrant) by encounters with the idea of _saliency maps_ in the perceptual processing literature. The visual cortex is thought to compile _saliency maps_ of stimulus material. So that is what motivated the use of _map_. The use of _bounded_ is perhaps self-explanatory: word-like clusters of letters are bounded by white space (though the white _in_ the word is part of the map).\n\nThe use of _bouma_ that original sparked my interest is contained in Hrant's comment on TYPO\\_L (early 1999): \"According to my lectures in cognitive science, the combined outer \\*and\\* inner outlines (but in blurry, para-foveal form) of a word is what we rely on the most; and that’s in fact the bouma.\"\n\nFor Insup Taylor and M. Martin Taylor (Hrant's source), who introduced the term _bouma shape_ in 1983, the term refers principally to a string of numerical coefficients that code distinctiveness when several (though perhaps not enough for my liking) internal measures (like 'the expressedness of the body') beyond the raw pattern of neutral, ascending and descending characters are taken into account.\n\nPeter Saenger appropriated the term from Insup Taylor and M. Martin Taylor to give substance to a notion of \"each word a distinct image\". The implication being: that's what we rely on. This is a notion consistent with Gerrit Noordzij's views on the history of writing.\n\nHrant's \"but in blurry, parafoveal form\" probably has its source in Taylor and Taylor's statement that \"[t]ext could in principle, be read when the letters are too small, blurred, or distant to be consistently identified correctly, provided their gross features could be seen. These are the conditions that prevail during parafoveal viewing of words to be foveated at the next or the second following fixation.\" (But experiments with the effects of 'crowding' (read: visual interference) _in the parafovea_ suggest that if these 'gross features' are the internal features (like 'the expressedness of the body') that underwrite distinctiveness, they can not in fact be 'seen'. This, incidentally, may be what is behind Hrant's more recent emphasis on 'envelope distinctiveness'(Typo#13) (at the expense of \\*and\\* (blurry) 'inner outlines') to preserve a notion of recognition in the parafovea)\n\nI suggested in another post that the term _bouma_ is a fitting tribute to a key figure, Herman Bouma. Though Herman Bouma and his associate at the Institute for Perception Research in Eindhoven, The Netherlands, Don Bouwhuis, ended up pursuing (with important caveats!) a letter based approach to visual word recognition (involving--like Kevin Larson's model--a perceptual stage and a decisional stage), it was Herman Bouma who said (1973) \"word recognition is an event much more complicated than just the combining of a number of recognized consecutive letters.\" And it was Herman Bouma who also first sensed the contribution of 'visual interference' to the process. (Visual interference is crucial to the binding implied in _bounded_).\n\nSo the question is: does my derivation have merit? The rest is to provide some context.\n\n",
  "author": "<a href=\"/web/20100825012846/http://typophile.com/user/6083\" title=\"View user profile.\">enne_son</a>",
  "time": "<br>",
  "uid": "6083",
  "comments": [
    {
      "time": "",
      "content": "I think you have succeeded beyond my imagination in describing how & why the term has come to us. That's great.\n\nThe only nit I would pick (maybe) is with the term 'bounded'. And only because unlike the rest of your post it isn't something that seems clear right away. When I read bounded map I am thinking about ideas like - demarcated by white, or wrapped, or something similar - but the idea of a 'border' is what comes up for me. Borders are intended to be precise even if reality doesn't match.\n\nMaybe the phrase “but in blurry, parafoveal form” is where answer to my quibble lies. I think that the bounded isn't meant so much as a sharp but rather a soft definition. If that's the case then maybe a term that is softer than bounded could be used to suggest this softness. Maybe my ideas about the bound bounded emphasize precision more than is warrented. Reading some definitions I get mathematically bound vs unbound meaning finite/defined vs. infinite/undefined , there is the idea of limit in law, & the more old style venacular speech 'Our joy knew no bounds' & 'Your remarks exceed the bounds of reason'. And last the bounded meaning to bind or restrict. All of these cases seem to point more to precision or to a desire for precision than I think you mean. I can imagine a counter arguement being made... What do you think?\n\n"
    },
    {
      "time": "",
      "content": "Thanks Eben, I suppose all I would really want _bounded_ to call to mind is: delimited, having some definite extent in spatial terms, demarcated by background or white, which, judging from your reply it does. It doesn't concern me that the boundary might be thought of as well-defined or sharp, rather than blurry or hazy or fuzzy, because in foveal vision the demarcation between foreground and background, information and noise (a paper stock with a 'tooth' has noise--nice noise), appears distinct _but isn't 'thematized'_--it doesn't become a feature, so to speak, subject to devoted processing routines. I don't believe the boundary or 'envelope structure' is separately thematized (or separately responded to as such) in parafoveal vision either, though I do believe definite information is captured there about extent (and coarse but accurate information about internal composition as well--too coarse to spark visual wordform resolution and a sense of perceptual connectedness with the words on paper, but accurate nonetheless.)\n\nIt might help you to know that one area where I disagree with Hrant is that the wholistic response bias isn't shattered in foveation such that processing becomes _letter_ recognitional (or at best bi- or trigram-recognitional) rather than remaining fully wordform resolutional. Parafoveal vision, meanwhile, is unable to acheive wordform resolutional closure, or so I've come to think.\n\nSo because it still evokes many of the things I think it should (also indirectly the idea of cross-letter-cluster binding), and because some of the things I think it shouldn't (like 'bordered', or 'boundaried') are probably knocked out by it's association with (information) _map_, and because it provides a nice anchor for the _bou_ of _bouma_, I guess I feel inclined to keep it, at least as a mnemonic--something to remember the meaning of the term by.\n\n"
    },
    {
      "time": "",
      "content": "Well, I'm happy <cite>somebody</cite> is keeping track of this stuff! :-) I myself am lousy at housekeeping (at least when it comes to interesting things).\n\nFrankly though, terminological derivation has always seemed too \"academic\" to me. I don't mind people using my preferred derivations or making up their own or anything in between - as long as when we actually use the term enough of us can understand it sufficiently well. Your \"bounded map\" thing can work - it reminds me of \"pixel\" being (supposedly) derived from \"picture element\" - although I've heard challenges to that.\n\nEben I think has a point about the exactitude of \"bounded map\" when talking about what a bouma really is. But, as above, I don't mind, simply because the definitions of \"bounded\" and \"map\" are nicely fuzzy of themselves!\n\nI don't mean to sound dismissive - this stuff <cite>is</cite> interesting to me,  \notherwise I wouldn't have lasted these ~7 years studying it!\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "It's not so much derivation as _grounding_ that I'm after, _anchorage_. I don't mean to be cute, but such grounding can discourage or constrain slipshod extensions or referential drift (besides making the term more transparent to a meaning / less opaque). And the kind of fuzziness _bounded map_ contains still gives us room to move.\n\nI wouldn't say this if I didn't think the susceptibility to drift is real.\n\n"
    },
    {
      "time": "",
      "content": "Having not investigated these thing except by proxy I can only refer back to what you both say you are getting at & look for holes if I see any.\n\nPeter, when you remind us that bouma is a term that is relevant both when text is in focus & when it is just starting to be perceived (before focus actually occurs) - I find my reservations about using the term 'bounded' retreat. This is because at some point it really is bounded in a fairly tight, crisp & precise way. Tight enough in my view to justify 'bounded'. You also say, \"delimited, having some definite extent in spatial terms\" and even if it's splitting hairs I would have to say that yes; even when out of focus, text has some sort of range of blur that is limited.\n\nHrant, I agree with you about 'map' & 'bounded' in reality or RL as the scifi folks say - but I am not so sure about the linguistic intent. There I think the intent, albeit fruitless at some level, is to nail things down & make them certain.\n\nPeter, you mean 'Drift' as in obscuration as opposed to alteration, or enhancement - no?\n\nCertainly most english words drift a great deal over time if all you mean by drift is change. Whether the change is good in any of these cases depends where you stand.\n\nAlso while I do think it's worthwhile to try to bring this word child up right for now; you must realize that it is going to have go out on it's own one day and get it's own apartment etc.\n\n;-)\n\n"
    },
    {
      "time": "",
      "content": "\"it’s worthwhile to try to bring this word child up right for now [but] you must realize that it is going to have [to] go out on it’s own one day and get it’s own apartment etc.\"\n\n:-)\n\n[referential drift]  \nI guess I mean alteration to the point where it becomes difficult to connect a current use with the original intent. The term's meaning becomes diffuse, rather than more clearly defined. I've though Hrant's stretching of the his use of the term to include single letters in focal vision might suffer from that. The original intent seemed to be to provide a term for a multiplex unit with an internal and external figural distinctiveness or uniqueness subject to processing by our vision-ware as one thing.\n\n\"the intent [...] is to nail things down\"  \nBut different people will feel inclined to nail it down differently and the term needs enough 'surface' for that, without the term loosing its basic shape. For example Peter Saenger will nail _bouma shape_ down one way in _Space Between Words_ and Insup Taylor and M. Martin Taylor will nail it down a different way in their _Psychology of Reading_ and their nailing it down might be sufficient to suit the needs of their subject matter and make their claims appear compelling, while still being mutually compatible. When I want to ask questions about receptive\\_field stimulus\\_information\\_integration behaviour within the visual cortex, I may feel the need to nail it down differently again. These ways needn't conflict.\n\n"
    },
    {
      "time": "",
      "content": "Peter, I see your point, but can you really prevent this except by deliberate negotiation? Maybe that's wht you are doing here.... I see. And certainly I can see some reason to try to be clear about the terms definition or it's utility goes away.\n\nThe question that comes up next is can you craft both a definition that you & Peter Saenger, M. Martin Taylor etc can agree on and which is going to to be specific to your professional concerns and at the same time create a sort of budget model definition useful to type designers. I for example might be willing to wade into the field of jargon ( that is legitimately neccesary to persue your work - that was not a crit at all! ) to attempt to understand what you mean - but most folks who design type are going to want a sort of workhorse definition. It seems to me that there is room for both. After all what a chemist means by sugar & what I mean by sugar when i go to the grocery store do overlap to a significant degree but the grocery store definition cannot be said to be nearly as precise.\n\n"
    },
    {
      "time": "",
      "content": "\"can you really prevent this except by deliberate negotiation\"  \n\"can you craft both a definition that you & Peter Saenger, M. Martin Taylor etc can agree on and which is going to to be specific to your professional concerns and at the same time create a sort of budget model definition useful to type designers\"\n\nProbably not. The most I can ask is that Peter Saenger, Hrant, and the Taylor's say: I see what you're doing and why, and it makes good sense to me. Now this is how what you say relates to how I use it.\n\nFor normal everyday use I could be happy for now with:  \n**bouma** :  \n[from **bouma shape**]  \nDefinition:  \nA configured whole or _bounded map_ of interdependant internal figural components.  \nExplanation:  \nType design, typography and our reading-ware treat words in text visually as bounded maps of _visual (con)figural_ 'stuff' to be process as a whole, not first and foremost linguistically as _letters with assigned orthographic identities arranged in an agreed-to order_ to be processed bit by bit. \"The natural form of reading is not by spelling or syllabification, but by grasping word wholes, i.e., word forms or configurations, constituting the units of perception in reading.\"  \nMotivation:  \nThe reason to push beyond terms like word _wholes_ or _forms_ to expressions like 'bounded maps of figural stuff' is to give these terms substance and sharpness, a greater specificity or definition. And to forestall inadequate formalizations of them in empirical testing situations.  \nPractical import:  \nAmong other things, this makes distinctiveness of the figural map, bouma distinctiveness, important for efficient processing, or readability.\n\n"
    },
    {
      "time": "",
      "content": "Sounds good. Except the reliance on \"word\", which is misleading. Words stand out, because of the power of the blank space, but they're just a special case of a broader scheme.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "If, as you seem to be suggesting Peter, bouma is simply a more rigorous and sharply defined alternative for 'word wholes or forms', then I think you and Hrant, and probably you and I, are disagreeing about what the term implies. And when you explain your derivation in this way, I'm less comfortable with it than I was previously. Words are bounded in an obvious way by the white space between them (at least in our writing system; not, I should note, in all writing systems). And I agree that 'grasping word wholes' is the central act of reading: words are what we are always trying to recognise. But I have been understanding Hrant's use of bouma as part of a particular model of word recognition -- one that I am not convinced by --, not as a any kind of synonym for a word whole. It seems to me that the most interesting thing about the bouma is that it may often not be identical to a word whole, but may be a recognised sub-word letter cluster. In this case, the notion of boundedness is less clear, although still relevant. Unlike the whole word shape which is visually bounded in our writing system, the implication of bouma recognition is that boundedness is internal, cognitive, presumably a function of pattern familiarity. In order to be able to recognise sub-word letter clusters, we would need to be able to discreetly separate them from neighbouring letters or letter clusters, i.e. imposing boundaries that do not exist visually on the page.\n\n"
    },
    {
      "time": "",
      "content": "John, I think you are right in sensing that for me _bouma_ is simply a more rigorous and sharply defined alternative for ‘word wholes or forms' and you are right in sensing that Hrant and I, and probably you and I, disagree about the specifics of what the term implies, or should imply. But we might still not differ fundamentally about how reading works.\n\nIn conformity with some of the the literature on reading and object perception, I would want to use the term, _tokeniztion_ for what Hrant seems to be alluding to with his \"broader scheme\" and you spell out with \"recognised sub-word letter cluster.\" _Tokeniztion_: the identification of meaning-bearing complexes in a character string where they are not physically marked--my gloss on an existing definition. And as you suggest pattern familiarity is key.\n\nSo I would need to add something like this to my explanation:  \nThe functional unit of perception in skilled fluent silent reading is a bounded map. Tokenization within the bounded map can occur. In unseparated text tokenization has to occur. In both instances tokenization imposes it's own boundaries. In separated texts, word spaces make a provisional, convention-based tokenization of the line of text available to parafoveal vision.\n\n"
    },
    {
      "time": "",
      "content": "The reason it's boumas and not whole words is that letter-cluster frequency & distinctiveness, and even semantic context do allow us to pick out smaller-than-word wholes out of long words - in fact we prefer to, because it's generally more efficient. This is for example why \"readjust\" is so hard to read.\n\n\\> we might still not differ fundamentally about how reading works.\n\nIf so, I'd love to hear John affirm  \nthat he doesn't think Kevin's angle  \ncan be the Real Deal.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "Sorry, I think parallel letter recognition could well be 'the real deal', but this is not the same as it being the full deal. I still think the evidence for parallel letter recognition as the primary process in reading is quite persuasive: certainly persuasive enough not be be discounted. And -- you'll hate this -- we shouldn't discount the possibility that bouma recognition itself involves some parallel letter recognition. This is not something that has been examined, and it seems to me that if bouma recognition is important to word recognition, as you believe, you have solved the mechanics of word recognition by introducing the problem of the mechanics of bouma recognition. :)\n\n"
    },
    {
      "time": "",
      "content": "\"Real\", \"full\", whatever, I think you need to make explicit that you don't  \nbelieve Kevin (that the PL model truly explains the mechanics of reading).\n\n\\> we shouldn’t discount the possibility that bouma recognition  \n\\> itself involves some parallel letter recognition.\n\nI don't get this, at least not the way I use \"bouma\". The main question really is, do we sometimes recognize certain clusters of letters as wholes in some cases, or do we always build everything from individual letters? Recognizing a bouma precludes worrying about its component letters - unless you regress to a bouma that seems to have been misread, and you foveate on the cluster to disambiguate it. The whole point of relying on boumas is speed - so there's no point bothering with the component letters of a bouma that's been \"confidently\" deciphered.\n\n\\> you have solved the mechanics of word recognition by introducing  \n\\> the problem of the mechanics of bouma recognition.\n\nWord recognition, the way I use the term (in the semantic sphere) is on a higher cognitive level than bouma/letter decipherment. In fact it's on a level beyond the context of type design or typography. The important/interesting thing for us is how the shapes get decoded (before they get to the semantic level) and the bouma model validates a bunch of things (like serifs) that the PL model does not. The two are fundamentally different.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "\\>the bouma model validates a bunch of things (like serifs) that the PL model does not\n\nI don't see why serifs can't be an advantage on the parallel processing model. To me they: 1. help maintain even color when letters are spaced widely enough for quick and easy letter recognition; 2. mark the baseline so the eye can follow the line more easily--thus requiring less leading than sans faces; 3. Help differentiate characters, also facilitating quick recognition.\n\nAll three of these qualities, if I am right about their benefits, would apply within the parallel processing model, I would think.\n\n"
    },
    {
      "time": "",
      "content": "John, when I said \"I think you are right in sensing that for me bouma is simply a more rigorous and sharply defined alternative for ‘word wholes or forms’,\" I probably should have said: actually _bounded map_ makes a statement about what for vision and the visual cortex a word whole in separated text is. It's a proposal for how we might want to think about 'whole' or 'form' or 'shape', when it comes to the visible word (if we want to sort out, without fear of ambiguity how visual wordform resolution or recognition works.)\n\nHrant, bounded map encodings form, and it is the encodings that strict visual wordform resolution _and tokenization_ rely on. This is what it means, in my scheme, to say reading is bouma based. A better counter to my introduction of _tokenization_ might have been: \"the reason it’s boumas and not tokenization is [...]\"\n\nIt's a question of which way of speaking can move us forward more effectively. Time will tell.\n\nJohn, I've tried to claim that what happens in the visual cortex happens massively in parallel, but that the mediating agents for visual wordform resolution are not specifically letter wholes but the totality of stems, cross bars, counters--as you say--in their pattern. In learning to read, encodings of words form that are indifferent to or cut across molarities (at the glyph level) and polarities (of black and white). (This is why it seems important to me to say the bounded whole is (for the visual cortex) a map of figural components at the role\\_architectural\\_particular and role\\_architecturally\\_evoked\\_form level, the stem / crossbar / counters / closure level.) There are persuasive arguments for this that can accommodate the empirical test results that make parallel letter recognition seem persuasive. But persuasive for one might not be persuasive for another. For another, what seems like a persuasive consideration to the one, might seem like special pleading.\n\nA bouma-concept is an invitation to see the word-whole under a certain aspect. Seeing it under this aspect puts our notion of 'whole' or 'form' inconformity with what happens in perceptual processing. It also provides a fertile basis for channelling our efforts in type design and placing type.\n\n"
    },
    {
      "time": "",
      "content": "Also, John, 'the mechanics [I want to say: 'perceptual processing mechanics'] of bouma recognition', or as I like to say 'visual wordform resolution' is the heart of the matter from a typographical point of view. And to stick with the terminological question, an understanding of 'word wholes' as _bounded maps_ provides opportunities for a specification of 'wholes' fit for empirical testing at a _perceptual mechanics_ level.\n\nA further note about tokenization:  \nTokenization to a letter or 'glyph-molar' level happens only in 1) learning to read, 2) letter-by-letter reading and 3) dechiperment of unfamiliar words. In separated text a single letter is a whole word. This is an argument against parallel letter recognition as the primary mechanism in word recognition. We can call it 'the tokenization argument'.\n\nWilliam, your \"when letters _are spaced widely enough_ for quick and easy letter recognition (my empahsis)\" begs the question _when_ that is. And is it different for quick and easy visual wordform (read: bouma) resolution, as I am inclined to believe? That is, is it wider than the currently accepted norm, which craft knowledge claims optimizes readability? And if it is wider than the currently accepted norm will it be possible to maintain, even with the help of serifs, an even colour or a vibrant texture?\n\n"
    },
    {
      "time": "",
      "content": "Further, I think serifs promote binding, and when they are abscent, there are greater pressures on spacing.\n\n"
    },
    {
      "time": "",
      "content": "I made an update to the inaugural post in this thread. It now reads: \"(But experiments with the effects of 'crowding' (read: visual interference) _in the parafovea_ suggest that if these 'gross features' are the internal features (like 'the expressedness of the body') that underwrite distinctiveness, they can not in fact be 'seen'.)\"\n\nOriginally it did not contain the words 'the effects of' and _in the parafovea_\n\n"
    },
    {
      "time": "",
      "content": "When & if the technical details are worked out I still want to encourage a workhorse definition. Actually, a workhorse definition might be composed or distilled from of those details that everyone already agrees on **first**.\n\n"
    },
    {
      "time": "",
      "content": "_I think you need to make explicit that you don’t believe Kevin_\n\nBut I believe him at least as much as I believe you. Sorry, Hrant, but I am not discounting or disbelieving any reasonable explanation of the reading process at this stage because I simply don't think we have enough solid knowledge, only conjectures. The parallel letter recognition model happens to be supported by a number of empirical studies, and also conforms to what we know about how the brain seems to handle other processes, so I certainly am not going to say that I don't believe it. I'm not convinced that it explains everything about the mixture of speed and accuracy of mature reading, but on the other hand it is obviously a sufficient explanation during the time we are learning to read. This suggests to me that parallel letter recognition might be _the primary reading mechanism_, and anything else such as bouma tokenisation and recognition is a developed extension that improves reading speed and accuracy but is not essential to the basic cognitive operation. It is pretty obvious that we can read without relying in any way on bouma recognition; what is of interest is the degree to which bouma recognition might contribute to reading _well._\n\n"
    },
    {
      "time": "",
      "content": "\\>William, your “when letters are spaced widely enough for quick and easy letter recognition (my empahsis)” begs the question when that is.\n\nMy comment raises your question, but it does not beg it. Question-begging is the fallacy of simply reasserting the issue under debate. I was not here asserting that we read or don't read using 'boumas'--the issue addressed by Hrant--and so was not committing the fallacy.\n\nI was arguing is that serifs are plausibly of value to the reader under the parallel processing models as well as bouma theories. So the values of serifs is not, to my thinking, a crucial test between competing theories.\n\nIf the theories were precise enough to specify optimal spacing - and that would be fabulous if they were - then maybe a crucial test could be done.\n\nI have hunches about optimal spacing, but not any well formed theory.\n\n"
    },
    {
      "time": "",
      "content": "_I don’t get this, at least not the way I use “bouma”. The main question really is, do we sometimes recognize certain clusters of letters as wholes in some cases, or do we always build everything from individual letters?_\n\nMy point is that we don't have a tested model of bouma recognition. To say 'we sometimes recognise certain clusters of letters as wholes' is begging the question: you are making assumptions about _how_ we recognise those clusters. Let's say we have a letter cluster 'bed' and a letter cluster 'bad'. We have two possibilities for recognition, both entirely reliant upon distinguishing the middle letter of the cluster, since that is the only difference between them:\n\n1) we recognise the cluster as a whole, taking into account the impact on the appearance of the whole of the middle letter.\n\n2) we recognise the cluster by recognising the individual letters that make it up, essentially applying the parallel letter recognition model to sub-word clusters in the same way as we do to whole words.\n\nIn either case, I reckon a huge amount of bouma recognition rides on context if we're talking about cues in the parafovea. I don't think there is sufficient distinction between bed and bad to be recognised with certainty in the parafovea, so we make a best guess based on context which is either confirmed by subsequent fixation content (in which case we proceed) or is not (in which case we regress).\n\nI know you won't like the second option because you have been happily assuming the first, but hopefully you see that it is a reasonable possibility and something that should not be discounted without testing.\n\n"
    },
    {
      "time": "",
      "content": "Peter: _I’ve tried to claim that what happens in the visual cortex happens massively in parallel, but that the mediating agents for visual wordform resolution are not specifically letter wholes but the totality of stems, cross bars, counters—as you say—in their pattern._\n\nI like this explanation a lot. But I don't sign up to ideas just because I like them :)\n\nIt seems to me pretty evident that you, Hrant and I do not, in fact, 'agree fundamentally about how reading works'. There is some commonality, but still a lot of disagreement. For my own part, I don't have a commitment to any particular explanation, and my interest is in keeping the options on the table and exposing unconsidered possibilities as they occur to me from reading what you and Hrant write.\n\n"
    },
    {
      "time": "",
      "content": "The passage John quotes is also the one that enables me for the first time to understand your theory clearly, Peter.\n\nIf I get it right, then, after learning the individual letters that make up a word like 'thought' (not phonetic), we mentally go from the pattern of bowls and counters and stems to meaning, without one of the intermediate steps being an identification of individual letters, and assembly into words. Do I understand you correctly?\n\nI still think that the ease of reading scrambled letters militates against your view, and for the importance identifying letters as part of the cognitive process.\n\nBy the way, even in Chinese while there are twenty thousand some characters, there are something like 200 'radicals' that compose the characters, and far fewer, I believe, in most characters. So even in reading these symbols it is likely, I suspect, that an 'assembly process' is going on.\n\nAs I have said, it would be exciting if you could derive some testable views on spacing or letter forms. Then whether you are right or wrong it would stimulate an advance to test your views.\n\n"
    },
    {
      "time": "",
      "content": "William, in your next to last post, you are right, I should indeed have said that the comment 'raises the question'. My 'begs the question' was slipshod.\n\nYou also say: \"[i]f the theories were precise enough to specify optimal spacing [...] then maybe a crucial test could be done.\"  \nI think my theory is precise enough to specify an optimal spacing, and that it has to do with stems and the vertical components of bowls--and maybe the means of angular components--, hovering about a rhythmic mean, but not hovering too tightly. This is the basis of my interest in fourier transforms. The idea is that, when the vertical components on either side of a letter like an o or an n are in synchronicity with the vertical components of the adjacent letter on either side, the pattern of the whole supersedes the molarity of the parts and makes resolving them effortful.  \nThis leaves the question of a critical test. I think it is in principle testable, but I don't have a handle on just how to structure it. There is some existing research that seems to come close, for example: _Effects of alphabeticality, practice and type of instruction on reading an artificial script: An fMRI study_, by Tali Bitan, David Manor, Istvan A. Morocz, Avi Karni (available on line at [http://splweb.bwh.harvard.edu:8000/pages/papers/morocz/cogn\\_brain\\_res.Bi...](http://web.archive.org/web/20100825012846/http:/splweb.bwh.harvard.edu:8000/pages/papers/morocz/cogn_brain_res.Bitan2005.pdf \"http://splweb.bwh.harvard.edu:8000/pages/papers/morocz/cogn\\_brain\\_res.Bitan2005.pdf\")).  \nThe scrambled text phenomenon that you mention in your last post before this reply raises interesting questions. How easy is reading scrambled text really? It seems to require some work, or at least some introduction to the underlying scramble protocol, before becoming manageable. How is reading speed effected? What pattern of eye movements become apparent, compared to those used in immersive reading of normal text? How quickly does fatigue set in? Is there a greater reliance on tokenization of still intact criterial word parts?\n\nAlso in your last post before this reply: your summary indicates to me you got what I mean, though I'd want to clarify what is meant by 'mentally'. I'd want to argue that, through learning, sense becomes neurally encapsulated with the bounded map or patterned whole. This is why with visual wordform resolution, _a perceptual process_, the connection with 'sense' is immediate.\n\nJohn, I'm hesitant to go into the bed / bad thing, because I think how we conceive parafoveal preview and the contribution of semantic context has to be turned on its head. I've tried to specify just how in a set of questions to Hrant and Kevin to follow up our suite of Typo\\_13 contributions. If you wish, I could fly it in a new thread, but like most of my exploratory stuff, it's full of 'ennesonese'.\n\nIn an earlier post you said \"[t]he parallel letter recognition model happens to be supported by a number of empirical studies, and also conforms to what we know about how the brain seems to handle other processes, so I certainly am not going to say that I don’t believe it. \"  \nI think your unreadiness to commit yourself one way or the other is fair. But I think your claim that \"[t]he parallel letter recognition model happens to be supported by a number of empirical studies\" is misleading.  \nKevin sought support for his claims about word recognition by pointing to the results of a series of empirical studies. But the results of some of these studies could just as easily sustain a model such as I am proposing, and the results of at least one of the others rely on a confounding of the bouma-concept, with 'word shape' in its \"raw pattern of neutral, ascending and descending\" meaning. Kevin's claims may be compatible with the results, but on their own the data provided by the studies he cites \"do not constrain the space of possible models\" to just his, or one, or to just the parallel letter recognition model of word recognition. (In the quoted phrase just above, I'm alluding to a comment about model confirmation in _Word skipping: Implications for theories of eye movement control in reading_ by Marc Brysbaert, Denis Drieghe, & Françoise Vitu).  \nAlso, what we know about how the 'how the brain seems to handle other processes' is--Kevin would be the first to admit--incomplete. And especially what happens in the visual cortex before text enters the cognitive stream is far from adequately understood.\n\nIn addition, I wouldn't call what happens in learning 'primary', except insofar as it has to happen for learning to occur. If the paper I linked to earlier in this post is any indication, we will have to say that what we think of as skilled reading of continuous text is an event much different than the effortful process of serial letter-wise or bigram / trigram-wise tokenization and sounding out, not just a faster, more parallelistic version of the same routine.\n\nEben, you are right about how a workhouse definition might come about. Now I might try:  \nbouma: the bounded map comprised by the totality of stems, cross-bars, bowls, counters, between-letter shapes, angular components, and the like, in their pattern. This is what we use, etc...\n\n"
    },
    {
      "time": "",
      "content": "Willian, one more thing, I don't think of what is going on in the visual cortex as an 'assembly process'. I think of it as a trace recognition process. As stimulus-provoked impulses move through the structured neural mass, where all kinds of processes of integration, enhancement, averaging and squeltching occur, at a certain point the system will recognize the trace pattern of neural spikes passing through the system. This will happen even with something as complex as radical-based symbols. But like with words in alphabetic western texts, the visual-cortex-ware must be 'trained'.\n\n"
    },
    {
      "time": "",
      "content": "\\> I don’t see why serifs can’t be an advantage on the parallel processing model.\n\nIn the PL model serifs can't help, and they would probably even hurt, because all they add to the decipherment of individual letters is noise. This is why some studies have actually shown that sans fonts are <cite>easier</cite> to read - because such studies are confined to deliberative reading.\n\n\\> 1. help maintain even color when letters are spaced  \n\\> widely enough for quick and easy letter recognition\n\nSo you're saying:  \n- sans fonts have less even color than serif?  \nAND/OR  \n- loose letterspacing helps readability?\n\nAnd concerning even color, the way you're using the term here (properly, unlike in that even color thread) I don't see how it helps in anything more than preventing errant saccades - and that's an extreme event that's easy to avoid, without really making everything \"even\" at all.\n\n\\> 2. mark the baseline\n\nThere's no reason to believe this happens. And even if it did, the only way it could help is to save space, not aid reading.\n\n\\> 3. Help differentiate characters\n\nExactly which characters are mainly differentiated by their serifs?\n\n\\> serifs promote binding\n\nExactly. They make individual letters less themselves and more parts of wholes. This speeds up reading, in a simple scalability sort of way.\n\n\\> details that everyone already agrees on\n\nI dunno about this getting-everyone-to-agree, on anything.\n\n\\> I believe him at least as much as I believe you.\n\nAgain, avoiding what you need to say... You have no problem detailing how you disagree with me, but you never make explicit that you disagree with Kevin about anything.\n\n\\> conforms to what we know about how the brain seems to handle other processes\n\n?  \nQuite the contrary.\n\n\\> it is obviously a sufficient explanation during the time we are learning to read.\n\nChild's play. Literally. We spend a small fraction of our lives learning to read. Focusing on that is like only making all-caps fonts.\n\n\\> we don’t have a tested model of bouma recognition.\n\nAnd as long as we're stuck in cruise-mode testing (the stuff Kevin does) we'll never be testing anything that can help us <cite>improve</cite>.\n\n\\> a huge amount of bouma recognition rides on context\n\nYes, something I've repeated at every opportunity. But this has no bearing on type design (except to validate the bouma model).\n\n\\> you, Hrant and I do not, in fact, ‘agree fundamentally about how reading works’.\n\nNo. But we do agree that the PL model is <cite>at best</cite> incomplete.  \nBut only two of us explicitly admit that.\n\nWe agree enough, for example, to state that serifs help.  \nThe PL model counters that.\n\n\\> So even in reading these symbols it is likely, I suspect,  \n\\> that an ‘assembly process’ is going on.\n\nNo, that's too slow.\n\n\\> How easy is reading scrambled text really?\n\nOne interesting thing that Luciano Perondi\\* has found is that this is easier to do in some languages than others. To me though, reading scambled text precludes good use of the parafovea - so yes, you can read, but never approach your full speed.\n\n\\* I'll alert him to this thread.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "Hrant, I think William is correct in suggesting \"that serifs are plausibly of value to the reader under the parallel processing models as well as bouma theories. So the values of serifs is not, to my thinking, a crucial test between competing theories.\"\n\nHere is how I rationalize William's claim:  \nFrom a perceptual processing point of view serifs affect saliences (and saliencies modulate cue-value). Herman Bouma and Cyril Latimer, and possibly some other researchers, hypothesize that some parts / features of letters or zones in their map have greater cue value than others. So if a serif marks an important zone or a cue-value-rich component or feature, it will make it more salient and heighten the recognizability of the glyph.  \n(There might also be an argument from 'well-formedness'. 'Well-formedness' is a gestalt-theory consideration (and for gestaltists a perceptual processing requirement).)\n\nI can see both a wholistic (whole-wordform resolutional) processing oriented researcher and an analytic (parallel-letter recognitional) processing oriented researcher accepting the above as a working hypothesis without jeapordizing their paradigm.\n\nWhere they take it will be different. A wholistically oriented researcher might hypothesize that under appropriate spacing conditions serifs have the added benefit of making the 'whole' more robust or well-formed as a whole or perceptual entity, and that that is good, because automatic tokenization to the letter or glyph-molar level is inhibited. A researcher with an letter-analytic processing bias might hypothesize that just because of that--just because of the inhibition of glyph-molar tokenization through lateral interference--letter spacing should be wider than most type-involved people think it should. And [s]he will want to show that a readbility advantage can be documented.\n\nSo the values of serifs is not a crucial test between competing theories. While predictions about spacing, premissed on notions of lateral binding / lateral inhibition that have functional-anatomical teeth might be. To me having functional-anatomical teeth means conforming with robust knowledge about signal tuning, signal integration, signal squelching and signal summation routines in the visual cortex, i.e., robust knowledge of lateral interference / integration.\n\nIf the researcher with a 'letter-analytic' bias finds that looser spacing does not produce the documentable readability advantage he or she expected, he or she will try to adjust their paradigm without jumping ship. Sometimes that will produce explainations that are byzantine or inelegant in their complexity. This is what happend to the Ptolemaic picture of celestial mechanics--epicycles within epicycles. And than a Copernicus comes along and realigns everything.\n\n"
    },
    {
      "time": "",
      "content": "\\>all they [serifs] add to the decipherment of individual letters is noise\n\nNo, serifs add the qualities I mentioned, not just noise.\n\n\\>\\>Exactly which characters are mainly differentiated by their serifs?\n\nNot 'mainly'--the main features are preserved in sans faces. But I think serifs make differentiation easier. For example, the serif on the top of the n's stem makes the n look more different from an o than is the case for a sans, perhaps making it easier to recognize, particularly in context of other letters.\n\n\\>So you’re saying:  \n- sans fonts have less even color than serif?  \nAND/OR  \n- loose letterspacing helps readability?\n\n'No', and 'oversimple'. Sans can have even color, but as Tracy points out they normally need to be more tightly spaced to have even color. However, I think Peter is on to something about having a set rhythm which is then slightly disturbed by where vertical elements hit one way and another--something like syncopation in music.\n\nMy pet theory is that the absence of serifs makes it difficult to achieve good spacing for readability, probably because the narrrow space between stems violates optimal rhythm in a wide face, such as Helvetica. I think things like Meta and Vesta read better because the ratio between the counter and space between letters is better.\n\nThinking about this now, I am thinking that one of the reasons even color is important is that it might ease identification of what is a 'word' in the parafovea. In other words, if you have an evenly grey blob with a space, then another evenly colored blob, it might help to plan the next jump of the eye.\n\n\\>loose letter spacing.\n\nThere is obviously such a thing as too loose space and too tight spacing, but what is optimal is not easy to ascertain.\n\nPeter, I sort of get the idea of what you are talking about as regards rhythm, but not fully. There are two aspects to making it testable. One is to specify it with sufficient precision that it will potentially be contradicted or connfirmed by further observation. the second aspect has to do with the logical links of your spacing ideas to the 'bouma' theories. If you can't derive it logically from you Bouma theory then a test of your spacing idea won't reveal anything about the larger theory. Similarly, if you can't show that your idea of spacing contradicts the parallel processing by letter assembly idea, then you won't have a crucial test, enlightening though it may be.\n\n"
    },
    {
      "time": "",
      "content": "William, without you immersing yourself more fully in the literature I refer to, and without me experimenting with ways of articulating what I see until something clicks with you or others, it will be difficult for you to follow completely why I put things as I do. The two things you say are necessary for my processing model to be testable are precisely what I try to do with my talk of molarities, polarities, spatial frequency channels, response bias, lateral interference, inhibition of glyph-molar tokenization and the rest, as well as my use of fourier transforms. (And why I try to push beyond where Hrant has left things.) I use these abberations to be specific about what happens in the visual cortex and to connect my sense of what happens there to an overarching scheme. That you don't see this means I have to work harder to make plain what I see. I'm not sure trying to stick with normal everday language will get us there. We require terms that describe events at the visual cortext level.\n\nType-involved readers want a work-horse definition. So a concept has to respond to both needs.\n\n"
    },
    {
      "time": "",
      "content": "\\>not sure trying to stick with normal everday language will get us there.\n\nYes, I have not read the literature on the question of readability, so I am fumbling. On the other hand Einstein, said that the beginning of any theory is an idea and not a formula. To explain a theory fully in lay language is not something I would expect, and is unreasonable to ask. But to explain its basic idea, so you get what it is about, and how it differs from competitors, is usually possible. So I am a little suspicious of the jargon.\n\n"
    },
    {
      "time": "",
      "content": "\\> I am a little suspicious of the jargon.\n\nI am not. We would not get nearly so far so quickly if we didn't have words like 'counter' 'serif' 'ascender' etc.\n\nJargon is jargon\n\n• only to those who don't see the use/definition of the words in use -yet-\n\n• or when these words are used when simpler words would in fact suffice.\n\nI think Peter does end up using a certain amount of 'ennesonese' as he says or 'jargon' from time to time (example 2). But it seems to me that he is making an effort to avoid jargon for it's own sake in general and I think those of us who are interested aught to try to meet him half way if we want to argue/discuss this bouma-bounded-word-shape-parafovea-thingy...\n\nActually - I wonder who funds research into this kind of stuff. I imagine it isn't all that well funded or there might be more people working in the field. Wait a minute I really don't know how many people are working on this now. Peter?\n\n"
    },
    {
      "time": "",
      "content": "William, do you get my basic idea and how it differs from Kevin's and pushes beyond Hrant's? Have phrases like 'supersedes the molarity of the parts' helped?\n\nLateral inhibition is relatively easy to explain at the ganglion cell level. It is far more difficult to discuss at the visual cortex level. Perhaps as difficult as it is to discuss elementary particles and how they interact.\n\nI do my best, using words I come across that strike me as relevant, and sometimes remixing them. When one works against the grain in a domain that has acheived a high degree of sophistication, one needs to be creative. The danger is that one can end up looking like a quack.\n\nEben, plenty of people do research on the psychology of reading and a lot of it comes from pedagogical and remedial interests, far fewer delve into the perceptual processing mechanics and have type interests. This shapes where we look for relavent data: in the cognitive stream, or in the visual cortex.\n\n"
    },
    {
      "time": "",
      "content": "\\>We would not get nearly so far so quickly if we didn’t have words like ‘counter’ ‘serif’ ‘ascender’ etc.\n\nIt is pretty clear what is the referent of serif and ascender. When a concept is more abstract, like 'bouma', problems are more likely. When you start relating two more abstract concepts, then things can really start to get fuzzy. It may be that \"molarities, polarities, spatial frequency channels, response bias, lateral interference, inhibition of glyph-molar tokenization\" all have very clear definitions and are needed to explain the theory. If so, I don't have any basic problem with them, although a brief definition would be helpful.\n\nKevin, the research psychologist and third part of the Hrant-Peter-Kevin set of papers as I remember had the least jargon.\n\nPeter, no, 'superceeds the molarity of the parts' is not clear to me. I do understand, I think, one way your views are different from Kevin's. I'm not sure I understand Hrant's.\n\n"
    },
    {
      "time": "",
      "content": "[William]  \n\"When a concept is more abstract, like ‘bouma’, problems are more likely. When you start relating two more abstract concepts, then things can really start to get fuzzy.\"\n\nor complicated, yes\n\n\"It may be that “molarities, polarities, spatial frequency channels, response bias, lateral interference, inhibition of glyph-molar tokenization” all have very clear definitions and are needed to explain the theory. If so, I don’t have any basic problem with them, although a brief definition would be helpful.\"\n\nSo it is unwise of me to let out my developing ideas in a forum such as this unless I want to lay out in full detail all the unfamiliar terms I use or my idiosyncratic use of them, and how they all interrelate. In lieu of definitions I often try to put a simpler version beside the more technical term.\n\nKevin's paper in Thessaloniki and Vancouver was directed at a general audience. I used the Thessaloniki venue mainly to address concerns I had about his conclusions and how he reached them. This may have seemed like a misjudging of the composition of my audience. But I felt it was important for the audience to get the sense that things were not as straightforward or the reasoning as innocent as Kevin's presentation seemed to make them seem, and that my complaints had some teeth.\n\nWould it have helped if I said 'supercedes the 'partness' or the 'independent unitness' of the parts? The first seems slighty off in the way the second isn't. Both are grammatical aberations, the second more than the first, though both are perhaps more familiar.\n\n"
    },
    {
      "time": "",
      "content": "Peter, it probably doesn't matter what terminology you use if you are able to produce testable results. But I personally find that the effort to write as clearly and concretely as I can forces me to clarify my ideas. So trying to avoid what Fowler calls 'abstractitis' I think is a good idea methodologically. But honestly only the result matters. If complex terminology is your way to get to a good theory, go for it. If not, try another way.\n\nAs far as being clear, if you describe contrasting scenarios, what you are saying will be a lot clearer to readers. For example: 1. the parafovea is able to distinguish words to the right, and plan a jump. 2. jump. 3. the brain in the initial step identifies all differentiating features of a word simultaneously. 4.... and so on.\n\n"
    },
    {
      "time": "",
      "content": "\"I have not read the literature on the question of readability...\"\n\nWilliam, you need to read material that addresses the matter of _perceptual processing_ in reading, and that will include material that addresses reading at the mechanical level of neural signal processing: how atomic (= unitary) pulses, originating on the retinal surface are combined--here I might indeed use assembled--to give the visual cortex an impression of the feature map (all under the supervision of a wholistic response bias). Literature thematically focussed on the question of readability doesn't usually address this.\n\nWhat happens with impulses originating in the fovea, where rods and cones project to a dense mosaic of ganglion cells and then enter the parvocellular stream, where there are additional layers of processing?\n\nWhat happens with impulses originating beyond the fovea, where rods and cones project to a much less dense mosaic of ganglion cells and then enter the magnocellular stream?\n\nHow is information from the two streams integrated? At what level?\n\nKevin has a special theory of lateral inhibition that applies to signal integration at the ganglion cell level (and it appears to be robust), but has, to the best of my knowledge, no _explicit and tested_ theory of lateral inhibition or signal integration that applies at the higher levels of the visual cortex. Probably different implementations of the same general principle apply at all levels, and there are currently judged to be 4 to 7 involved in reading. I know of no detailed model that has worked this out in algorithmic terms.\n\nTo fully assess the difference between my proposals and Kevin's we will need explicit theories and a set of models that predict behaviour at this level, at the neural mechanics level and develop a test which can reveal things about these processes relative to immersive reading.\n\nKevin knows this as well as I do and we are both informally committed to making moves to pursue this, but without you or others getting into the details at this level my descriptive proposals may continue to seem frivolous or needlessy cumbersome to many, and we will continue to go around in circles about the need for them, or the usefulness of bringing them into discussions of matters like the importance of serif or divergence. I bring them in where I think a discussion has become gridlocked and they might get the discussion moving again by pushing it to a deeper level in the perceptual processing domain.\n\nI would be happy if others joined the effort to clarify what happens at the neural mechanical level in the visual cortex, and could propose simpler terms that make mine redundant.\n\nI wrote the above before your latest post.\n\nIn reply to the second paragraph in your latest post, I tried to describe contrasting scenarios visually in my Typo\\_13 contribution, figure 6 an 9. Figure 9 illustrates the last paragraph on page 24.  \nFigure 6 is here: [http://www3.sympatico.ca/penneson/pe\\_figure\\_6.pdf](http://web.archive.org/web/20100825012846/http:/www3.sympatico.ca/penneson/pe_figure_6.pdf \"http://www3.sympatico.ca/penneson/pe\\_figure\\_6.pdf\")\n\nThe correct version of Figure 9 is: [http://www3.sympatico.ca/penneson/pe\\_figure\\_9.pdf](http://web.archive.org/web/20100825012846/http:/www3.sympatico.ca/penneson/pe_figure_9.pdf \"http://www3.sympatico.ca/penneson/pe\\_figure\\_9.pdf\")\n\nI also find that \"the effort to write as clearly and concretely as I can forces me to clarify my ideas.\" I try to avoid abstractitis, but I don't see any benefit in avoiding abstractions when they are called for. Frequently they are, but that is a judgement you might not share. That being said, I do enjoy serious terminological play, and it probably shows.\n\nIn your: \"the parafovea is able to distinguish words to the right\" I would have problems with \"distinguish words\". What does 'distinguish' mean? It is too open a term to discuss visual mechanics and the specifics of saccade-generation. The most I can confidently assert is \"assembles accurate ensemble statistics about\" (not my terms, though I've adopted them), and the parafovea doesn't _do_ it, the ganglion cells do it on the basis of information the parafovea supplies. Etc. What do these ensemble statistics look like or give information about? We are still not sure. More testing needs to be done to tease that out.\n\nThe point is, if we want to explore and weigh Hrant's idea of bouma identification in parafoveal vision to the point where his conclusions might become fruitful for channelling typographic practice, we will have to be clear about (specify) how \"distinguish words\" needs to be understood. Sorry William, I see no other way.\n\n"
    },
    {
      "time": "",
      "content": "addition to the above:\n\nWhen you lay aside the 'niave-realism' notion that the visual cortex simply and mysteriously draws an internal representation on a mental canvas and then matches it to tokens in a database, things become a whole lot more complex, but also more exciting. It's like answering the question: if atoms are mostly empty space, how is it that we experience things as solid?\n\n"
    },
    {
      "time": "",
      "content": "\\> I would have problems with “distinguish words”.\n\nI wasn't putting forward a theory, just giving an example of a scenario with 'dummy text' of somewhat vague words. My point is that of C.S. Peirce in his essay 'How to Make Our Ideas Clear': the more we identify the practical consequences of our concepts the clearer they are. So I think \"serious terminological play\" gets in the way of clarity. But as I said, if you are able to use your terminology and get to testable results, more power to you.\n\nI'm not going to study this issue properly, as it will take months (at least) to do it right, and other work presses. I just wanted to bring up a methodological issue. But there is no one path to innovation. Whatever works, works. If terminological play works for you, and in the end gets a testable version of your interesting ideas, fine. But if you find that you are stuck with that, then my suggestion is to 'operationalize' it: make in-principle testable, concrete scenarios.\n\n"
    },
    {
      "time": "",
      "content": "\"But if you find that you are stuck with that, then my suggestion is to ‘operationalize’ it: make in-principle testable, concrete scenarios.\"\n\nThat is what my terminological proposals seek to promote: suitable operationalization. Operationalization is not the _alternative_ to what I try to do. It _is_ what I try to do with all the plain language and terminological resources I can muster. You are unhappy with my _way_ of doing it and the consequences. In my Typo article I complained about Kevin's paper's 'inadequate operationalizing' of the construct 'word space', and I explore avenues to operationaliize the construct more adequately. Which is why we need the specificity potential provided by the bouma-concept.\n\nThe reason for my challenge was for you to put yourself in my shoes. I would love to see what your terminological appartus might look like after suitable immersion, or what the terminological appartus of the both of us together might look like after suitable immersion.\n\nDid Charles Saunders Pierce say 'practical'? Functional-behavioural consequences at different levels of processing in the visual cortex are one thing; consequences for practice quite another. Both enhance clarity. I try to explore both. Which is why I try to articulate a specific proposal for rhythmic spacing using fourier transforms.\n\nI don't think I am leaving aside things that need to be done where I can (I don't have access to a lab or team of researchers; but I do have fourier processing plugins), and doing less relevant things instead, out of the context of what needs to be done.\n\n"
    },
    {
      "time": "",
      "content": "\"I wasn’t putting forward a theory\"\n\nI realize that. I was trying to show that the moment you scratch the surface of plain language when you try to import it into scientific domains that explore functioning in a detailed way, you run into trouble.\n\n"
    },
    {
      "time": "",
      "content": "another try at 'independant of their molarity'  \nindependent of the the fact that various subsets of components in the total bounded map form independant stimulus units or glyphs on their own, on the basis of their contiguity, attachedness or connectedness,  \ni.e., independant of the glyph-unit-partness of the parts\n\n'independant of their polarity'  \ni.e. for the visual cortex, _both the white stuff and the black stuff within a bounded map_ have information value that goes toward recognition, again, 'in its pattern'--both the black stuff and white stuff _are_ information susceptible to compact encoding in a unitized way to facilitate retrieval: the visual cortex works with the black and white together, at the stem / counter, etc. level, in their conjunction.\n\nDoes this help?\n\nAll this makes rhythmic spacing important. Hrant will probably want to say black / white balance (= notan)\n\n"
    },
    {
      "time": "",
      "content": "More to: \"all this makes rhythmic spacing important\"\n\nIf the spacing is too wide, so that the internal and external whites (within the bounded map) are out of synchronicity and the vertical components out of phase to the point of setting up competing spatial frequency peaks rather than one dominant spatial frequency peak (with harmonic frequency peaks dependant on that one), the visual cortex will be inclined to interpret the retinal imput data _according to_ molarities and more dependant on the black. The efficiencies gained by compact _encodings_ (of material across the bounded map) _at the stem / counter, etc._ level will be lost.\n\n"
    },
    {
      "time": "",
      "content": "Peter - would you expand on that last post and maybe show us some examples? What for instance do you mean by 'out of synchronicity'? I think I know what you mean but without looking at something I feel unsure.\n\nI ask this because I have an idea that this idea of your relates to that pet idea I had about textfaces/notan/caligraphy etc. This is the one I mean:\n\n[http://typophile.com/node/14816](http://web.archive.org/web/20100825012846/http:/typophile.com/node/14816 \"http://typophile.com/node/14816\")\n\nI would like it if somebody would respond to that thread too - hint! hint!\n\nI would also like to add that other ideas you have expressed in text would be easier for me to apprehend if there were visual examples too. I know it would be alot of work and that not all the ideas lend themselves to being shown. Still, if you you don't ask...\n\nThanks!\n\n"
    },
    {
      "time": "",
      "content": "Eben, while you were posting your post, I was preparing the following (I do think my last post and your thread are related; expanding /providing illustrations is the long-term plan):\n\nAfter a representative but not exhaustive search of the google-store of material about bouma and bouma shape on line, and in the context of the above, I suggest that for general use, or as a workhorse definition, we stick with the Paul Saenger gloss of the term or go with the widely available wikipedia definition.\n\nHere is what the wikipedia makes of it:  \n\"the shape of a cluster of letters, often a whole word\"\\*  \nSaegner's gloss:  \n\"each word a distinct image\"\n\nIf we need or want to discuss word shape or reading at a deeper level than this allows, I suggest we use the expanded notion of bouma as _the bounded map of salient whites inclusive af the black_\\*\\* to guide us in our thinking about word shape and reading. So the word shape of the word is its map or distinctive pattern of salient whites, inclusive of the black.  \n• this puts our thinking about shape and recognition into congruency with an, I think, robust notion of how the visual cortex processes word-like-stimuli;  \n• it discourages 'easy operationalism' by calling to mind more with the term word shape than is usually meant in the cognitive scientific, perception-science and neurological literature on reading (beyond 'envelope structure' and 'raw pattern of neutral, ascending, and descending characters,' it encodes internal figural form elements)  \n• it channels action in productive directions, encouraging us--when working with existing types, or devising new ones--to think about the whole, and the white, divergence and the visual integrity of the word image\n\nSo for purposes of discussion I will call the word shape of the word its distinctive map or pattern of salient whites, inclusive of the black. And when I say reading is bouma-based I will mean by this, that this is what the reading person orients his or her attention to for the purposes of perceptual processing: the bounded map of salient whites, inclusive of the black.\n\nDigging even deeper has additional benefits. Things like the importance of spacing becomes apparent. Things like the importance of space craft becomes apparent when we specify a perceptual processing scenario or scheme and the neural signal transmission mechanism underlying it.  \nHere is a new try at describing my scheme:  \nLetter parts, not letter wholes, are the mediating agents in word recognition. In fluent reading of well-formatted continuous text, assembling letter parts into their letter wholes, as an intermediate step (I call this: componential abstraction), does not spontaneously occur. (This contradicts Kevin) The perceptual processing routines that underlie word recognition go from the disturbance of the bounded map (or field) by letter parts to the pattern of the salient whites. The pattern of the salient whites inside the black is what we most rely on. What we see is the map of salient whites inclusive of the black. And we see this particular map as this meaning-holding word.\n\n\\* The full wikipedia entry reads:  \nThe term bouma (pronounced \"bowma\") is sometimes used in the work of cognitive psychology to mean the shape of a cluster of letters, often a whole word. Some typographers believe that, when reading, people can recognize words by deciphering boumas, not just individual letters. The claim is that this is a natural strategy for increasing reading efficiency. The term bouma is a reduction of \"Bouma-shape\", which was probably first used in Paul Saenger's 1997 book \"Space between Words: The Origins of Silent Reading\", although Saenger himself attributes it to Insup & Maurice Martin Taylor.\n\nThe bouma as 'reduction' quip makes me think of my 'bouma as bounded map' as an 'expansion' (this could be further expanded to 'bounded difference map')\n\n\\*\\* _the bounded map of salient whites inclusive of the black_ is an attempt to come up with something more succinct than: \"the bounded map comprised by the totality of stems, cross-bars, bowls, counters, between-letter shapes, angular components, and the like, in their pattern.\" It is also slightly differently skewed.\n\n"
    },
    {
      "time": "",
      "content": "RE: 'the bounded map of salient whites inclusive af the black'\n\nI really like this. Even though you mean to parcel out & define with this phrase ( not a bad thing ) I find it contains some of poetry and vigor that bouma & notan signify to me.\n\nYour breakdown is useful too.\n\nTo me it seems like a workhorse definition should include both the idea in that phrase & phrase 'the shape of a cluster of letters, often a whole word'. The idea doesn't seem complete in either one alone.\n\nI also think some of the language could be made easier without compromising the idea - words like 'salient', & 'bounded map' seem like good places to attempt substitutions. I don't know if I can do it but I'll give it a stab. Even if I fail I will come closer to understanding what you mean. I don't have time today but maybe later this week.\n\nThanks for pushing this topic along. You are doing 90% of the heavy lifting!\n\n"
    },
    {
      "time": "",
      "content": "This is still pretty rough...\n\nBouma is \" the combined visual features of lights and darks, usually darks shapes bounded a ligher color, made by grouped forms in printed or written or on-screen communication.\"\n\nI wrote this to try to use more common language while avoiding talking about shapes or other kinds of misleading specifics. I also wanted to write a definition that allowed for bouma in the context of non western forms like Hindi, Arabic & Chinese. I am sure it's pretty weak since it's a just a 1st draft but hopefully the idea I am trying to get across is there in seed form.\n\nI realized while writting this that I am unsure that elipisis ( ... ) could be said to have a bouma shape. I think intuitively it must because it is a combination. Whereas a period cannot because it is just one form. Still, a One in Chinese is a single stroke - and it seems somehow counteruintuitive to deny it a bouma shape...\n\n"
    },
    {
      "time": "",
      "content": "Eben, what seems to be missing from your definition is the idea of the bouma as subset group of forms within a word (unless the word is short enough to consitute a bouma in itself). Perhaps you want something like this:\n\nBouma is 'the combined visual features of lights and darks ... recognised as a discreet unit of grouped forms in printed or written or on-screen communication.'\n\nYou raise an interesting point: can a bouma consist of a single typeform, or does the term always imply a group? I'm half inclined to say that bouma should be defined precisely by that act of recognition, or tokenisation, so a bouma is as large or small as what we recognise discreetly. In terms of the kind of role architecture that Peter has described, it is even possible to consider that a bouma might be smaller than a single typeform.\n\n"
    },
    {
      "time": "",
      "content": "Eben, I like \"made by grouped forms\" but I think we've lost the sense of 'in their pattern' that 'map' provides.\n\nIn following the recent arabetic threads at ATypI I came to realize 'bounded map of salient whites inclusive of the black' is convenient for the western scripts, but useless for arabetic scripts where recognition at the word level seems to rely heavily on the disturbances provided by arrhythmia and amplitude and facingness to simple undulance, at the junctures between graphemes--seems to rely on action at the junctures. The interesting thing is: the script forces perceptual attention away from the 'gravitational centre' of graphemes to the junctural action pattern--the action where the left and right ends of graphemes meet--, accented / inflected by the pointing system. Interestingly, the characteristic fourier transform of texts in arabetic scripts looks very different than a text in a latin script. It operates as it were on a different premise.\n\nThe question becomes, do we need a different term to name this or do we try to adapt the term bouma. At the moment I would opt for a different term. So we would say reading of semitic or latin-derived texts is bouma-based, while reading of arabetic texts is.... This does not preclude a deeper commonality. In both cases the perceptual system must attend away from the center of gravity of the bricks.\n\nJohn, I think it is fair to ask, can a single token be a unit of perception or recognition in reading, and I would say it could. I think though that the questions the term bouma seeks to answer are: in a cluster, is the unit of _perception_ in recognition in fluent reading of continuous texts the individual tokens in the cluster, or the cluster as a whole; and, if it is the whole, are the 'mediating agents' in processing the tokens, or their parts in their pattern, or is there only the envelope structure or raw pattern of neutral, ascending and descending components? So to my mind the good sense of using the term evaporates when we try to use it in reference to letters, or components of letters.\n\nI would say tokenization happens when the word is long or complex and there is a familiar item in our bouma-store that corresponds to the part currently in foveal vision. (And when this happens a process of completion occurs.) So tokenization is bouma-based.\n\nEben, in reference to your other thread you might want to explore Thomas Milo's work on allographic typography.\n\n"
    },
    {
      "time": "",
      "content": "John, you are right that I didn't use the word 'word'.\n\nI didn't & don't take my phrase \\*too\\* seriously since I don't have the expertise or understanding ( yet ) to craft a good phrase. And I knew somebody would be there to bring up the point!\n\nI guess I was trying to avoid that issue for now to concentrate on the possibility of making bouma a term that might be applied to non-western writting systems too. I would like Bouma to be a term that is as universal as it can be. I don't know how universal that can be. But I would like to know. In science and culture there is a tempermetal tendency to be a lumped or a splitter. I recognize that I am more of a lumper. It's just my temperment.\n\nOriginally I started my attepted definition with some word/word subset/tokenization language but then I started adding phrases that related to radicals in Kanji/Chinese charcters realized that Hiragana (the non-Chinese derived japanese forms) were maybe not covered yet, there was the problem of the Chinese 'one' character and that I had no language to describe hindi, urdu or Arabic - and so I glossed this aspect.\n\nI do recognize that this is maybe a big problem because the idea or the 'word shape' was I think pushed over to allow for a more nuanced idea of 'the shape of a cluster of letters, often a whole word'. So there is a link that has to be adressed.\n\nHowever, look at what this new phrase does! It is both more inclusive and broad but also much more precise. No small feat!\n\nI suppose I thought that tendency or direction might be continued.\n\nThat pretty much described my motivation for using that kind of phrasing except of course for my already admitted interest in relating bouma to Notan. Since my (quite possibly naive) view of Notan includes Chinese Japnese caligraphy (probably other kinds too) and the since the definition of Notan relates closely to Bouma I was also motivated to consider these links too.\n\nObviously the 'way' we read varies with the script/language used but there are a ton of relevant pralells too. 'Bounded map' for instance might be used just as well with any script type - not just western ones.\n\nPeter,\n\nI agree with you about the loss of the idea of pattern. And I see how 'map' provides that in a professional context but I still don't know that a non-techincal person or art/design student is going to get the sense from the phrase 'bounded map'. Not right away anyway. I'll have another go perhaps & see what I can do there. Obviously it's a really useful phrase and can't be tossed out lightly.\n\nI am not sure if you are right about the arabic. Sure the script is structured very differently but it is still a pattern of lights & darks with readable salient features. It doesn't seem to me that we can talk about bouma (or notan) in the context of Chinese or Japanese & not allow it for Arabic. Arabic can also takes alot of extreme forms where salient features are stretched - but doesn't always have to. There are also condensed arabic forms. So it is especially tough to compare. Tougher both because of the profound variety of expression within it & it's inhernet structures. But the way I see it toughness doesn't get us off the hook.\n\nI guess that I think that if it is possible it would be good to separate the 'Bouma' definition from reliance on the processes specific to reading western texts. Maybe it should be a term that relates to the parcelling of visual stimulus alone. I am not saying that we should not use bouma to describe a reading process - not at all.\n\nBouma seems like a great candidate to describe parsing of raw perception, whereas other words like Tokenization do a good job of describing interpretation. It seems preferable to me just now because Bouma is freed from script specific arguements over how we read but still does a good job of describing a genuinely interesting, useful and complicated idea about the visual stimulus.\n\nLet me ask you both about the idea of tokenization. I am not clear I get this.\n\nhere are 3 contrasting examples: 'start' '3' & 'modernization'\n\nWith 'start' the token & bouma shape happen to be the same. I think there is no disagreement about this.\n\nWith '3' I wonder if you can say it has a bouma. It seems like you should be able to say it does according to my visual only definition anyway. Accidentally it is also a token too. I think...\n\nAnd then there is 'modernization' There 'token''iz'& 'ation' are the tokens or maybe 'modern' & 'ization'. But the idea is that we parcel whole sections of the word visually ( bouma ) and that we can then make meaning from these clusters ( token ).\n\nMaybe parcelizing & interpretaion are too close to separate.\n\nI'll have to check out that Thomas Milo.\n\n"
    },
    {
      "time": "",
      "content": "Eben, I don't see the 'much more precise'. I would have said: more diffuse, and less crisp!\n\nWhen you dropped the parcelling of visual stimuli phrase I had a moment of envy. My issue with Kevin's model is all about how the visual cortex parses / parcels.\n\nQuickly, I think tokenization is unlikely to happen with 'start'; tokenization happens around the 'modern' of 'modernization', but not around the 'ization', because there a completing mechanizm takes over. In '3' tokenization doesn't need to happen, and it only makes sense to think here of recognition being bouma-based in a derived sense--according to my sense of it, that is.\n\nI have not considered some of the other script sytems you describe fully enough to comment about them, but I'm inclined to say 'bounded map' could apply to chinese / japanese scripts. But what I would put after 'of' in relation to them is unclear to me. I'm not sure it would come out 'bounded map _of salient whites_ etc.\n\n"
    },
    {
      "time": "",
      "content": "\\> I’m not sure it would come out ‘bounded map of salient whites etc.\n\nI am not surfe why. What does the 'of' indicate? The thing is I can read japanese ( a tiny bit ) and there is in hiragana a close paralel to lettering in that each form relates to a sound and is not usually indicating an idea all by itself - unlike the more complicated chinese characters. But despite this complicated and rich set of reading behavior - I am still registering shapes or 'parcelling of visual stimuli' since you like the phrase. And I am still looking at black & white. So why not a bounded map? Is bounded part of bounded map related to the discreet forms - the separateness of letters? If so, Japnese has it in print, except sometimes with the chinese charcters Kanji which could be said to be running together, but then each Kanji is separate too so maybe each one of those could be considered bounded... But in a running script this boundedness ( if that is what you mean ) goes away. But then quickly written Western cursive lacks this boundedness too.\n\nI am speculating all over the place now.\n\nArabic is unusually complicated so maybe we can leave it to one side until I am following your idea better.\n\nBTW I tried out the phrase 'parcelling of visual stimuli ' to see if I could undergird the idea of separating a kind of universal Bouma characterized by visual stimulus/perception from one a Bouma whose definition was inexticably linked to western text. Maybe it's too late. Maybe thats wrong headed.\n\nWhat do you think?\n\nIt would be fun to sit with beer & a napkin & show my examples... Maybe in Boston in July.\n\n"
    },
    {
      "time": "",
      "content": "I think it might be futile.\n\nWhen I look at chinese characters I don't have the same sense of containedness of space by the black, so I am not confident about the 'of salient whites' part in 'bounded map / pattern of salient whites...' with chinese characters in a block or cursive script. And I don't have the same sense of the closedness or enclosedness of the figural complex I do with words in western writing either. So I'm hesitant to transpose the concept to the chinese script domain. It seems less applicable. I don't want to force it. And I don't want to loose what 'bounded map of salient whites inclusive of the black' adds to a notion of word shape beyond what is usually meant by it in studies of reading.\n\nWith chinese writing I get more of a sense of marks that together have a unique and quietly assertive clusteral signature, tightly packed but not clogged to the practiced reader, and without a definable silhoutte structure--I'm trying to find apt words here.\n\nLike the arabetic samples Thomas Milo shows in his allographic typography pdf there seems to be less reliance possible on the pattern of salient whites in recognition. The eye seems to be forced on to a dependance on other features of the map. (There's something here like recognizing an animal has been here by the tracks, as if an idea has alighted here...)\n\nThe initial appeal of parsing / parcelling was on a different level for me than the bouma-definitional level. I was thinking of the parsing done by the visual cortex at the role-architectural component level, and the parcelling of them 'independant of molarities'.\n\nBeer and examples would be good.\n\n"
    },
    {
      "time": "",
      "content": "\\>unlike the more complicated chinese characters\n\nIn Chinese characters, the compounded ones (with more than one radical) usually have part indicating the sound-a simpler character with the same sound but different meaning-and one part indicating the meaning. I forget whether the sound one is on the left or right, but it is systematic, I believe.\n\nPeter, going back to your commments on the importance of rhythm in the counters as they march across the page. I like the ideas, and it sounds like this could be put into a valuable, and maybe true testable theory. But I don't see why it couldn't also be made part of a parallel processing view. There the idea could be that good rhythm enables the eye to pick out individual letter quicker, but the processing is by assembly of letters into the word, and matching with a mental dictionary.\n\nFinally a general comment on the bouma vs parallel view. My old teacher Popper had the theory that the mind was actively, relentlessly testing our theories in order to understand incoming data. For example, the periodic reversal in optical illusions, such as the [Necker Cube](http://web.archive.org/web/20100825012846/http:/www.cut-the-knot.org/Curriculum/Geometry/Necker.shtml), he attributed to the brain testing and then failing to confirm one theory of the perspective, and then trying another theory.\n\nIf the brain is trying this super fast and multi-faceted hypothesis testing on letters and words, we might expect that every type of analysis is at work, maybe simultaneously. For example, short words like 'was' might be recognized immediately as patterns--the 'bouma' view--while if there is not such an immediate recognition an assembly process might be going on--or both in two tracks simultaneously, with one abandoned when context corroborates a guessed meaning. Also the brain might be guessing from first and last letters, and the meaning of the contextual words--explaining how we don't notice many typos. In other words, as soon as the brain gets a plausible hypothesis given the contextual meaning, it might just fly along further with that meaning, and only have the eye jump back if not confirmed, to look more carefully. For example, it is possible that the brain can identify words from a few individual letters without identifying a full bouma or doing a full assembly process. This could be tested perhaps by having words with missing or wrong letters and see how easily they are read.\n\nThos cxxld bx txxted by hxvxng wxxds wxth mxssxng or wxxng lxttxrs.\n\nThis reminds me of the fact that Hebrew is normally written without vowels, and that English, without vowels, is surprisingly easy to read without vowels, except for very short words.\n\nThs rmnds me tht Englsh is sprsngly easy to rd wtht vwls...\n\nThe way some words with missing letters are easy to read and others hard would probably tell us a lot about the process--maybe there's even a test here. Misspell word with a related 'bouma'--such as round letter replacing another round, and one with an ascender another ascender--or mangled letters with some feature of the original, then that should be much more quickly read than with letters replaced by words whose features are more different by salient features--or not, depending on who's right.\n\n"
    },
    {
      "time": "",
      "content": "William, to take every possibility you throw out and address it item by item would take much more time and resources than I have available. (Or maybe it's because it's late in the evening and I don't have the energy.) If you think some of the things you suggest have legs, try to develop them in dialogue with the avaiable data from neuroscience and perceptual psychology, studies of eye movements, etc. To me the terms of reference you use are too coarse and the reference to the brain trying out theories and hypothesis in a perceptual processing frame, too analogical to get very far.\n\nBut I don't think rhythmic spacing would naturally flow from a parallel letter recognition processing model where contextual interference is taken into account. I don't think it would be regarded as an consequence of a parallel letter processing view.\n\n"
    },
    {
      "time": "",
      "content": "Peter, I was just throwing out these ideas to see if anything seemed worth pursuing, or resonated with your thinking. If not, forget it.\n\nThe question of whether the rhythm idea is consistent with the parallel processing view has to be ascertained by developing a clear theory of good rhythm in type, and deducing observable predictions from the parallel processing view that are inconsistent with predictions from a bouma theory.\n\nA good theory of rhythm in type would have merit whether or not it discriminates between the bouma vs parallel processing view.\n\n"
    },
    {
      "time": "",
      "content": "William, thanks. The things you threw out resonated more with things I've read in the literature on reading than they do with my own thinking. But they do require consideration. I am on a different track but one that needs to be able to accomodate what transpires when the reader meets the kind of truncations you spell out. One of the things I do hold is that, when the reader trips over an unfamiliar word, a process is set in motion that is decipherment based, and tokenization to the letter level happens. Something like word-identity, pronunciation and meaning hypothesis testing might happen here. So there is some overlap at this level with your suggestions.\n\nOn the matter of spacing and rhythm, I'm using fourier transforms to get some kind of a stable benchmark for defining good rhythm. Then I want to describe a theory of lateral interference that guages the inhibition to molarization in a rhythmic system where stem-like agents are the items for processing. I think this will predict what happens to the Word Superiority Effect under different spacing conditions, and what response patterns (relative to accuracy and response times) we should see in a forced-choice test where spacing and format are the independant variables and co-varied.\n\nThen the question becomes, what kind of theory can best explain the pattern of results. And what results would test my confidence in my scheme.\n\n"
    },
    {
      "time": "",
      "content": "Eben, I am starting to shift my opinion about the applicability of bounded map to arabetic scripts. Though my sampling set is quite limited, it is clear to me now that in assimilative scripts the map of visual items is clearly bounded left and right.\n\n"
    },
    {
      "time": "",
      "content": ":-)\n\nMaybe I can post some examples on a new thread & ask you to comment on them. Maybe I can call the thread 'bounded map' or something. July is far away!\n\nThis is what I will be trying to get at with my examples: I thought that boundedness was something that you had been using in order to avoid fixating only 'black' and allowing for a more Notanic or whole view. A view that was aware of both the shape of letters and of the counters and in-between shapes.\n\nLet me try my idea out in a simple way here first: In western letterforms we have counters which are surrounded by black. Like in an 'O'. In this case for instance the white of the counter is a part of the bounded map as much as the white around the outside of the 'O' is it not?\n\nWilliam, your posts are intertesting but I have not left off trying to sort out basic terms yet to go on to reading theory yet. Thats why I haven't commented.\n\n"
    },
    {
      "time": "",
      "content": "Eben: _I thought that boundedness was something that you had been using in order to avoid fixating only ‘black’ and allowing for a more Notanic or whole view. A view that was aware of both the shape of letters and of the counters and in-between shapes._\n\nYes, that is what I am after.\n\nEben: _Let me try my idea out in a simple way here first: In western letterforms we have counters which are surrounded by black. Like in an ‘O’. In this case for instance the white of the counter is a part of the bounded map as much as the white around the outside of the ‘O’ is it not?_\n\nExactly.\n\nI think what might have thrown you off is my comments about Arabetic scripts. In your reply to those comments you asked: \"Is [the] bounded part of bounded map related to the discreet forms--the separateness of letters?\" In reply to this I say: no, it is intended to refer to the whole of the cluster.\n\nBut when I look at the items in this Thomas Milo sample:  \n [www.enneson.com/public\\_downloads/pe/fa\\_bi\\_tathbiitayni.pdf](http://web.archive.org/web/20100825012846/http:/www.enneson.com/public_downloads/pe/fa_bi_tathbiitayni.pdf \"www.enneson.com/public\\_downloads/pe/fa\\_bi\\_tathbiitayni.pdf\")\n\nI see a bounded map, but bounded--in the full sense of the word--on the left and right only. Top to bottom there is more of a dispersion pattern of marks across a peak / valleyed band. I don't get the sense that 'pattern of salient whites inclusive of the black' is descriptive of what is there, or what the visual cortex relies on. I might opt for something like: 'bounded map of marked and salient peaks, inclusive of the valleys, and inclusive of the markings: in their pattern. I am unsure of how to include the white, because it is rarely 'contained' except at the extermities left and right, and stuctured in the valleys.\n\n"
    },
    {
      "time": "",
      "content": "William [importance of rhythm]: _I don’t see why it couldn’t also be made part of a parallel processing view. There the idea could be that good rhythm enables the eye to pick out individual letters quicker..._\n\nIn a system that responds to salience, and gauges processing protocols by distance between stems, placing equi-distance above connectivity accross a salient gap, why / how would a rhythm where vertical blacks are in step and whites in synch promote rather than inhibit automatic processing according to molarity?\n\nAn encoding based on compiling statistics about the salient white strikes me as offering efficiences over one that is premised on going against the natural grain of visual processing and than reassembling the whole outside the visual cortex.\n\nAsk: what would the processing rule have to be in a field where visual gravitational forces (between visual subcomponents) and mass (saliency) rules behaviour?\n\n"
    },
    {
      "time": "",
      "content": "William, regarding your 'multi-faceted hypothesis testing' scheme, I'll say there are more than one routes to recognition, but it's not a horse-race between competing routes. When the preferred efficient 'non-molarizing' / 'pattern of salient-white compiling' route does'nt work because the cluster (or the part of the cluster that is in the form-resolving field) is unfamiliar, the system switches horses taking the longer and harder route to recognition, tokenizing to the letter level, with a subsequent (re)assembly process. A different set of signal-processing protocols kicks in, that will, over repeated encounters with the new word, lead to a boumatic shortcut / a compressed encoding. Also, the perceptual processes work on a principle of sufficient confidence, not absolute confidence. This leads to missed typos, etc.\n\n"
    },
    {
      "time": "",
      "content": "Peter, thanks for the examples.\n\nI guess I intuit what you mean about the Milo examples and white boundedness on the L&R sides. The trouble is that the tops also seem bounded to me. The black is surrounded by white. The meaning I am taking is like that of water. Water, for instance, surrounds islands. An island is bounded by water. See what I mean? I wonder if the bounded you mean has to do with the sweep of an eye over the text. Maybe you are suggesting that a text which has overly long ascenders (or has overly long descenders) ends up being read like an eye over a picket fence at close range. That would make the text (for a reader) 'not bounded' perceptually speaking - despite being litterally bounded by white. I wonder if in the case of the taller more extreme examples / styles of arabic text the point of focus is less tight and the Bouma idea is applicable after all. Also, the most extreme examples of this kind of writting is usually reserved for a title - not running text - but we are not experts. I would need to look into this quite a bit more. Still, as an example maybe arabic text is a good theoretical model to help me understand what you mean.\n\nThe next aspect I wanted to explore is common to Hebrew & chinese & Japanese. An abscence of word spacing. In all there texts you get a series of glyphs which share a common height ( no arabic style problem here! ). But there is a second variance with western text. One that arabic doesn't have. 'Words' are not separated. In Hebrew there might be texts where this is done now ( are there? I know modern hebrew uses quotes sometimes too...) but old hebrew did not do this. So in this way Old Hebrew might be violating an idea about bouma - that there must be word spacing. Chinese might not be said to do this because each ideogram can be perhaps thought of as a word. On the other hand the regularity of texts might be an issue. Japanese text is a hybrid. It uses Chinese characters but then also uses phonetic characters ( Hiragana & Katakana ) with no word spaces.\n\nThe last aspect I wondered about is the dense kind of Chinese character - one with many marks packed tightly. For some reason I had an idea that this kind of glyph would be be the sort of thing that would violate an idea about being 'bounded by white'. Now I doubt you would have a problem with it - but I would still like you to comment on it.\n\n"
    },
    {
      "time": "",
      "content": "Eben, thanks for pushing me on all this because it has generated many refinements to my thinking about where we should take the term. But I have to be a bit cryptic in reply because of other commitments.\n\nwrt paragraph 1 & 3:  \nDon't think _white_ boundedness; think: _map_ or _ **salient** (for vision) relevant- **component** (can be black and / or white in different quantities or proportions) **map** _\n\nwrt paragraph 2:  \nThink of this: for bouma-based processing to work there doesn't have to be word spacing. There only has to be a store of _(linguistic-) **sense-tagged** _ bouma-level encodings. (rote memorization of grammers in scribal schools might help build them--i.e., the encodings) In unseparated texts tokenization to the bouma-shape level has to occur for reading to proceed.\n\n"
    },
    {
      "time": "",
      "content": "Eben, Hebrew always has word spaces now, and has had for at least 2000 years. The spaces in Chinese are, as you say in effect word spaces. However, in reality most Chinese words are two syllables and two characters, not one, so the Chinese case doesn't quite fit either way.\n\nPeter, I haven't had time to work through your argument on why your theory can't derived from the parallel processing view, and I will be away from the internet, more or less, for the next month, but best wishes with the development of your ideas on this.\n\n"
    },
    {
      "time": "",
      "content": "Thanks William, we'll see where it goes. If you ever get a chance, read George A. Kelly's _The Psychology of Personal Constructs_ (1955: W. W. Norton & Company). (George Kelly is my Karl Popper.) It's fundamental to how I think about theory / practice and how I work with concepts. Or do you know it?\n\nIn relation to this thread:  \nDon't ask: do boumas exist; ask if the bouma-concept is a fertile construct--for 1) understanding perceptual processing in reading and for 2) channelling practice.  \n(That's not Kelly, but me--in the spirit of Kelly)\n\n"
    },
    {
      "time": "",
      "content": "William, sorry, I thought it was more recent than the last 2000 years! ha! Boy is my face red! Actually, was there ANY period in which there was no word space? In the case of Chinese there is still no 'word space' in the sense that we know it. Peter's ideas about bouma seemed related to this space.... But your right. It's in-between. Not here nor there. The whole idea of bouma could be reduced to western language only but I am not sure thats a good or healthy idea.\n\nPeter, I don't know where this leaves us. The second of the two responses makes sense to me. Your saying that it isn't the spacing in a litteral sense but rather the in the mental 'parsing' of signs. This make sense. To me anyway.\n\nThe first response seems less clear. When you have time to elaborate please do. I suspect that actually the same kind of idea applies - it's a question of how you parse the signs. I suspect that you & I might do it one one way. If the arabic speaker/reader does it that way is another sort of question. I am a very visual thinker. I may be suffeering from an over reliance on that outlook. Hence my camera-centric idea about visual focus with the attendant suggestion that moving the camera/eye perspective back to bring more of the parsable signs in is possible. And that that would accomplish a white boundedness. But you are saying that I am fixating on the wrong issue - no? I am still not sure where you would redirect focus however. Looking foreward.\n\n"
    },
    {
      "time": "",
      "content": "Eben, to talk sensibly about chinese / japanese and arabetic scripts I need to know more about them. The bouma issue is about how independant sense-units are coded and processed in reading of continuous texts. In reading of texts arabetic scripts it seems intuitve that what I have called 'componential abstraction' does not occur, except in learning the building blocks of the script. What I call componential abstraction is often called 'slot coding' in connectionist models of reading. Kevin Larson's model relies on slot-coding. Similarly in chinese / japanese scripts. While a character might contain a semantic radical and a phonetic component, I would guess that slot-coding of these components does not occur in practiced readers.\n\nI responded: \"Don’t think white boundedness; think: map\" because I felt we were getting hung up on it when trying to extend the bouma concept to chinese / japanese and arabetic scripts, and that when you heard 'bounded', this became 'bounded by white', which an enclosed map is, but that's not the point. The point is that there is a more or less definite point at which the shape-map ends. If a word in a western script is like and island, a word in chinese / japanese scripts is more like a delta and a word in arabetic scripts is more like an archipelago with an isthmus-like core.\n\nIn an assimilated arabetic script, certainly the central isthmus is bounded by white, but the sense of boundedness in the sense of the entire complex of isthmus and teeth having a definite boundry at the top and bottom is less strong than in western alphabetic scripts. Yet there is a strong sense of boundedness left and right. So bounded map applies to arabetic scripts in a different way. The consistancy of the white is also different. Except at the extremities it is not strongly contained, or contained to the point of saliency or 'psycho-activity', so it is hard to get a strong sense of a strong pattern of salient whites. There is some pooling of whites in the wells of the main form, but I suspect this is less tuned-to in the visual cortex than the marked peak pattern.\n\nThe point is that if we want to have a 'wholistically-skewed' term or replacement for 'gestalt' that goes beyond 'envelope structure' or 'raw pattern of neutral, ascending and descending characters' to help us talk about how linguistic sense units might be perceptually processed in reading, we might need to specify it slightly differently for different scripts.\n\nThere is a significant gain in exploring this applicability to other scripts, because it forces us to get clear(er) about the different _optical grammars_ of different script systems.\n\nIt seems that the evolutionary dynamic subtending the move into the future of every script system is toward an optical grammer where unitization of subcomponents at an independant sense-unit (= word) level is facilitated, bouma-distinctiveness optimized and (letter-recognitional) componential abstraction superceded.\n\n"
    },
    {
      "time": "",
      "content": "Right. This is where you seem going - the difference between a directly observeable optical form the visual grammer of that form, and the mental parsing of those signs. Obviously they relate to each other in some strong ways. But the maybe point of bouma is perhaps their intersection. Would it be fair to characterize bouma then as a visual unit of meaning mentaly parsed from a larger set of signs? I like this better because it focuses on the parsing first & then the visual. The unit is something you can map out on the signs & point to but is not the same as the signs - nor is it the same as the mental process alone. I imagine I may well made a mess of this - but what do you think?\n\nIf there is anything here in this then the advantage of it would be that it would be a definition that was less culturally bound that the one being used before. I find that more satisfying.\n\nI have to acknowlege that there is probably a powerful utility in having language specific terms. I guess am keen on bouma not being one of these for some reason. This despite the fact that I see now what your mean by cultuarl differences in a textual saliency map. My sense of the word had been so caught up with a visual definition up until recently that I found the idea of using bouma for western texts kind of sad. It seems lile a universal term is a more powerful term too...\n\nLike the term 'plural'. No matter how indicated in a given language - and it varies alot; plural is still a useful concept - even if you are comparing a language which specifies kinds or flavors of plural with great specificity to one which goes: One, two, three, four, five - lots/much/many. Still, we are talking 'plural'.\n\nYour comments about the 'point of saliency' seem skewed in favor of the utility of condensed forms. Why should that be? Isn't bouma the tied to the parsing event - rather than the relative ease or lack threof in the parsing process?\n\nThat is why I am not sure why the shape of a map - island, delta, or peninsula is important. Well, that's not quite what I mean - I mean maybe you can characterize them as having visual differences and probable attendant differences in the mental processing/parsing structures - but I keep imagining that within this diversity might be a kind common aspect to the parsing and that maybe this might be called bouma. It just seems like that has more utility than drawing a line in the cultural sand. Oh well, I am repeating myself now.\n\nCheers!\n\n"
    },
    {
      "time": "",
      "content": "Also would you elaborate about 'componential abstraction' or ‘slot coding’? Would be the act of consciously recognizing first a part of a word or a radical within a chinese glyph as part of the reading process?\n\nAbout 'bounded' - Are you saying that because western texts have such regular or predictable upper & lower shapes compared to arabic that the sense of a predicatble boundry is stronger and that the sense of boundedness comes from that predictability? If so I start to see that - but I wonder if that sense isn't just the product of unfamiliarity with the forms... Still, you may have a point.\n\n"
    },
    {
      "time": "",
      "content": "Eben,  \n1. Yes. Slot coding is recognizing the part first--or better, activating a (so-called) detector neuron for the part first--but it is not done consciously in reading, it is done automatically & subliminally (according to its proponents). I think it is not done period when encountering familiar words during immersive reading.\n\n2. My comments in my previous post were to explore the applicability of the bouma-concept to other script systems, not to raise doubts about its applicability as I had done earlier in relation to arabetic scripts (pardon the about face). One of the things I was trying to show is that such an exploration promotes a more intimate knowledge of what the visual cortex relies on optical-grammatically in other scripts compared to the western script. Does it rely on the white in quite the same way?\n\nIn arabetic scripts 'bound(ed)ness' is still a usefull construct (thinking about them in terms of their boundedness as wholes is a useful exercise), but words in arabetic scripts are bound or bounded in a different sense than words in western scripts. Bound by different mechanisms? The main real benefit to the concept is to force us to see words (parsed / parsable and parcelled sense units) in non-simplistic _visual-figural / integral-unit / object-like_ terms rather than _abstract-orthographic aggregate_ terms.\n\nTry to think of parsing / parcelling etc., in perceptual processing terms, not as 'mental' operations. That's the problem with many studies of reading: reading is seen as a chiefly mental cognitive process with a quite straightforward and relatively minor perceptual processing compontent. I say that in studies of reading the perceptual processing component is massively misunderstood. There are some signs that this is changing.\n\n"
    },
    {
      "time": "",
      "content": "Eben, I'm struggling to figure out how best to reply to your main comment above about characterization. I don't want to say what a bouma _is_ just _how I want to use the term_.\n\nEssentially I'm still stuck on 'bounded/bound map,' skewing my characterization of what it's a bounded/bound map of, differently for different script systems. \"Visual unit of meaning mentally parsed from a larger set of signs?\" doesn't get me where I need to be when talking about response bias and mediating agents in visual wordform resolution in reading. It talks about what is the object-correlate of the response bias (a sense-tagged visual unit), but not about what the visual cortex relies on to mediate recognition--the mediating agents in their pattern. For my purposes of grounding typographical practice in percptual mechanics I need more from the term (or another term)\n\n"
    },
    {
      "time": "",
      "content": "\"Type design, typography and our reading-ware treat words in text visually as bounded maps of visual (con)figural ‘stuff’ to be process as a whole, not first and foremost linguistically as letters with assigned orthographic identities arranged in an agreed-to order to be processed bit by bit. “The natural form of reading is not by spelling or syllabification, but by grasping word wholes, i.e., word forms or configurations, constituting the units of perception in reading.\"\n\nWhere Latin reading is concenred, this is a fantasy theory, so this fantasy definition can only do more real harm than fantasy good.\n\n"
    },
    {
      "time": "",
      "content": "David, when you design letters is your focus on shape, and how shapes interact, interlock or cohere in a word setting, or is your focus on phonetic assignments and spelling conventions? And what is a rhythmic word image important for if it is not fundamental to efficient processing in the visual cortex?\n\nThe neurological processes underlying perceptual processing in reading are indeed remarkable. I think my proposals are imaginative and fit the data. However, my proposals are incommensurate with current patterns of data-interpretation and appear counterintuitive when phenomena at the retinal, post-retinal and neuroanatomical level are not adaquately considered.\n\nThat you think of my proposals as fantasy indicates that I need to work harder to make them compelling, and that I need to work harder to make the alternatives seem awkward, ill-conceived or not explanatory enough.\n\n"
    },
    {
      "time": "",
      "content": "It's notable that David (not unlike many others in his -rarified- category)  \nhas however also rejected the Parallel-Letterwise model. I have to wonder:  \nWhat's in between? So more discourse is indeed needed.\n\n\\> I need to work harder\n\nBut no matter how hard we work at this, the reality remains that in order to make fonts that people like and people buy you don't need to really know how reading works. Anecdotal experience is sufficient for that. Note how all those nice fonts were made before Javal.\n\nThis is a classic case of mainstream versus pushy - and both have a place - it's just a matter of striking a good balance, which is entirely dependend on the individuals in question and the circumstances at hand.\n\nFantasy is relative - but so is Quality.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "I think there are different levels, or degrees, of observation with which we can observe Latin text-shapes in order to recognize them, thereby decoding their meaning.\n\n1. the shape of phrases  \n2. the shape of words  \n3. the shape of phonetic or syllabic letter groups within words  \n4. the shape of individual letters  \n5. the shape of letter parts\n\nIn fluent reading, we start from the top, doing only as much as is necessary to get the meaning, inferring the rest.  \nThe levels have been learned from the bottom up, a hierarchy of skills.  \nOn any given day, we may proceed differently through the levels, or do so on rereading.\n\nIn type design, the designer pays attention to making all these levels of recognition as clear as possible, because they are all relevant to the process of reading. So although the designer works on discrete letters (level 4), the context of the other levels is always in play.\n\nI think that boumas are dynamic visual constructs created by the viewer, prefigurations of what one expects to see next. The process of seeing/reading involves the creation of successions of boumas, from level 1 down, each bouma collapsing at the point of closure when meaning is deduced.\n\nBoumas are flexible shapes, envelopes, or conceptualized graphic relationships which are fitted over, and matched against perceptual data. They are a library (or toolbox) of patterns which one has learned.\n\nTypographers teach themselves the bouma of good letterspacing, aka even color; this is a non-linguistic way of reading text, a meta-level of control.\n\nA bouma is a specific kind of gestalt phenomenon.\n\n"
    },
    {
      "time": "",
      "content": "\\> boumas are ... created by the viewer ...\n\nPlease find another term for that idea.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "Hrant, What do you think of a non-western centric bouma definition? Worth a shot or a waste of time?\n\nPeter, do you do experiments/studies too? I could look this up I suppose but asking you is simpler & probably more accurate.\n\nNick - nice to see you on the thread. Would you care to contrast your idea in more detail with Peter's and or Hrant's?\n\nDavid, I think if you are interested in this you have to have a hypothosis & that this might well be fantasy - but that is a risk you run when doing research. That much is fair isn't it?\n\n"
    },
    {
      "time": "",
      "content": "I think the ideal definition of \"bouma\" would  \nin fact be independent of writing system.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "Eben, the only experiments I do are with fourier transforms. I haven't published anything on reading other than the _Typo#13_ text.\n\nNick, the more I read your post the more I like it.  \nWhile I've tried to use the bouma / bounded map concept to help me to formulate a more robust notion of word shape than current cognitive-science usage promotes, the idea of dynamic [prefigurative] visual constructs [...] from level 1 down [...] each collapsing at the point of closure [...] is massively appealling.\n\nReading involves a dynamic anticipatory visual indexing of parafoveally available text at the phrasal and word level, and upon foveation of the parafoveally indexed items, sometimes involves tokenization to the phonetic / syllabic or letter level--with letter-part discrimination as a last reort--to promote visual wordform resolutional closure.\n\nIf the core idea in the bouma-concept is visual information maps, it could be useful to distinguish word-maps, phrasal maps, sub-word maps.\n\nHrant, I agree. Hence my use of 'bounded map'; what is being argued here are basic principles of object perception and how they apply to perceptual processing in reading.\n\n"
    },
    {
      "time": "",
      "content": "\\> Reading involves a dynamic anticipatory visual indexing\n\nYes, but it arises from the boumas at hand; the probability-mapping of a bouma to an actual letter cluster is certainly guided by contextual expectation\\*, but the reader doesn't <cite>create</cite> anything in advance - that would be massively inefficient, and is not the type of thing the subconscious bothers with. Yes, we decide what a bouma is based on all the boumas we've deciphered before, but saying the reader creates boumas is utterly confusing.\n\n\\* Better than \"anticipation\".\n\nAlso: Anything beyond what's visible in a single fixation (e.g. entire phrases) is moot (I mean at the perceptual level).\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "\\>but the reader doesn’t create anything in advance\n\nYou're right, I got the creation in the wrong place. Dynamic boumas aren't created on the fly from scratch during reading.\n\nThey are originally created when one learns to read. They are memorized \"patterns\" (in the sense of templates) which may later be matched against perceptual data during reading.\n\nThey are created, in as much as learning is a creative process with personal and cultural overtones, and in as much as one makes a decision to create a useful memory.\n\n"
    },
    {
      "time": "",
      "content": "OK, much better, but: we don't decide to create memories.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "Hrant, about my use of 'anticipatory': the visual indexing of parafoveally available text at the phrasal and word level bears on what lies ahead in the visual stream. So it is anticipatory. Indexing what lies ahead (for subsequent foveal attention) and triggering grammatical expectations or determining their precise semantic loads are different things, though they work together. Indexing what lies ahead requires compiling ensemble statistics; triggering down-stream expectations requires a visual wordform resolutional event; connecting to the semantic load of the indexed items--word or phrase--requires a new fixation and a new visual wordform-resolutional event down-stream.\n\nI'm dubious about your mootness claim: entire grammatical phrases fall within visual parafoveal range at every line-of-type-medial fixation.\n\n"
    },
    {
      "time": "",
      "content": "\\> entire grammatical phrases fall within visual parafoveal range\n\n1) What do you mean by \"phrase\"?  \n2) In the best case still only really short ones.\n\nhhp\n\n"
    },
    {
      "time": "",
      "content": "Nick: _In fluent reading, we start from the top, doing only as much as is necessary to get the meaning, inferring the rest._\n\nI find this sentence very problematic, because I'm not sure that I understand what you mean by 'meaning'. This could be taken to imply that we 'get meaning' somehow independently of 'getting the text', and that we only get as much of the text as we need to get the meaning in 'fluent reading'. Something like this might be true of informational texts such as manuals, but we are more likely to be skimming the text in such cases than engaging in what I would think of as fluent reading, or immersive reading to use Hrant's phrase. Most of the time when I am reading -- novels, non-fiction works, journal articles, even quite a lot of newspaper content -- I am not getting meaning independent of text: the text _is_ the meaning that I am getting. I am 'getting' arrangements of clauses, phrases, sentences, parapraphs, etc., not a kind of on-the-fly paraphrase of the meaning of these arrangements.\n\n"
    },
    {
      "time": "",
      "content": "\\>we don’t decide to create memories.\n\nYes we do.  \nWe don't learn to read and write in a passive way, we actively train, forcing ourselves to memorize shapes, to imprint these ways of accessing information into the core of our being, as habits. Each one of us creates our own reading technique through intense practice, intellectual athletes.\n\n\\>I’m not sure that I understand what you mean by ‘meaning’.\n\nIt's it in relation to the level at which text is accessed. User defined.  \nIf a reader is skimming sentences in a mostly parafoveal blur, they're getting enough meaning (on their criteria) to not ponder every word.  \nThey may go back later, rereading, and sharply fixate on individual words.  \nWhere does that fit in the reading lab scenario?  \nWhat is the reader \"seeing\" when the words were long ago recognized and decoded, but reading continues and the meaning is still emerging?\n\n"
    },
    {
      "time": "",
      "content": "John, I took Nick's _[i]n fluent reading, we start from the top, doing only as much as is necessary to get the meaning, inferring the rest_ somewhat differently. I took Nick to be evoking a kind of probability summation mechanism in the visual cortex, where only enough processing of blacks and white--in their pattern--to promote sense-following need occur. And that this can happen at the phrasal level. Because at the bouma level words and phrases are overdetermined, confidence about identity works on the 'doing only as much as necessary' or selective processing principle. With wordform resolutional confidence comes connection with sense, often even on a phrasal level, because a location in sense- or meaning-space is encapsulated with each boumatic code, and bouma supercodes at a phrasal level might also exist.\n\nHrant, by phrase, I mean short strings of words, often two to three items in length. Interestingly, my Random house tells me that in Rhetoric a phrase is \"a word or group of spoken words that is perceived momentarily as a meaningful unit\". So a bouma string can have a single location in meaning-space encapsulated with it.\n\nNick, your way of speaking sometimes makes the processes you describes sound hyper-deliberative. I am reading your sentences as if that's not what you have in mind.\n\n"
    },
    {
      "time": "",
      "content": "\\> Each one of us creates our own reading technique\n\nEssentially: no. The necessities and mechanics of reading end up overpowering any personal variances, and we almost all end up reading pretty much the same way. The only thing that varying one's way of learning to read does is alter the point at which it \"clicks\" (which normally happens about age 10). All those teachers teaching us how to read are basically nannies, not shepherds.\n\n\\> If a reader is skimming sentences in a mostly parafoveal blur, they’re  \n\\> getting enough meaning (on their criteria) to not ponder every word.\n\nThat's not reading (in the sense of the word useful to us).\n\nHowever, I'm glad to see you're in fact a close subscriber  \nof my own theory of reading, at least in relation to Kevin.\n\nhhp\n\n"
    }
  ]
}
