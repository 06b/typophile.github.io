{
  "id": "34108",
  "title": "Opentype feature access to unusual characters",
  "forum": "Build",
  "tags": [
    "Build"
  ],
  "content": "Here are a few ideas:\n\nSuperior:  \n® becomes \"registered.alt\" -- a small, superior version of the character  \n† becomes \"dagger.alt\" -- a small, superior version of the character  \n‡ becomes \"daggerdbl.alt\" -- a small, superior version of the character\n\nStylistic alternates:  \n' becomes \"second\"  \n\" becomes \"minute\"  \nx becomes \"multiply\"  \n- becomes \"minus\"  \nl becomes \"liter\" (u+2113)  \n\\> becomes \"fist\" (u+261E)\n\nThese seem reasonably intuitive.  \nIs there any reason not to implement them?  \nAnything else that could be added?\n\n",
  "author": "Nick Shinn",
  "time": "29 May 2007 — 9:45pm",
  "uid": "2021",
  "comments": [
    {
      "time": "29 May 2007 — 10:30pm",
      "content": "I think the superior ideas are fine. There are quite a lot of characters that may take superior forms in some kinds of publications, and most do not have dedicated superior encodings in Unicode. So using the 'sups' layout feature is the obvious and legitimate way to access them.\n\nBut I disagree with your proposed stylistic alternates, because all the target glyphs do have their own Unicode encodings, and if someone wants those specific forms then they should use the appropriate characters, not disguise other characters as them. The fact that lots of people type x instead of × doesn't mean that the latter is a stylistic variant of the former; it just means that those people are using the wrong character. And who says that the fist is a stylistic variant of \\>? why not a stylistic variant of •? Thankfully, we don't need to play such guessing games, because we have ☞\n\n"
    },
    {
      "time": "30 May 2007 — 3:13am",
      "content": "I agree with your criticism in principle, but in practice it's very hard to find unusual characters in the glyph palette, especially in OT fonts with 1000s of characters. It always used to bug me looking for the \"second\" and \"minute\" in the Symbol font, with only 100 or so.\n\nPossible negative consequence of this stylistic alternates proposal: a document with a \"liter\" symbol is set in a font using the \"el-to-liter\" feature, but then reset in a font that just sets the plain \"l\"; or the fist comes out as \\>; or multiply reverts to x, etc. Is that so terrible? Surely the meaning is intact, although some typographic subtlety is lost.\n\n"
    },
    {
      "time": "30 May 2007 — 6:34am",
      "content": "I agree with John.\n\nMany of Adobe's early Pro fonts have similar kinds of substitutions (e.g. in Warnock Pro the ornaments are alternates of lowercase Latin letters), but this is not really a good practice\\*. These and other substitutions (like `sub [a A] by ordfeminine;`) were implemented in the font to make its usage convenient from the user's POV, but they're not good because they replace character(s) by other character(s). On the other hand, a substitution like `sub a by a.superior;` is perfectly legitimate, as long as 'a.superior' is left uncoded. (FWIW, a superior variant of the lowercase 'a' is not present in Unicode; although 'a.superior' and 'ordfeminine' U+00AA might look alike and even share the same glyph form, they are semantically different)\n\nThe bottom line is, OpenType layout (OTL) should not be involved in character transformations. The user is the one responsible for encoding his/her message appropriately, and this means using the correct codepoints, even if these are not readily accessible from the keyboard. The function of OTL is to style the message/content, not to alter it.\n\n\\* Unlike the 'fist', which is encoded in Unicode, ornaments are an interesting case because they don't have their own codepoint, so how should we access them/provide access to them? The current practice we're using is to treat them as alternates of the 'bullet'. This treatment does not apply to dingbats and other symbols such as arrows, since these generally have their own Unicode codepoints.\n\n"
    },
    {
      "time": "30 May 2007 — 8:42am",
      "content": "Nick,\n\nFor a comp anyway, the best way to enter such characters in InDesign is to enter the the Unicode number, not by using the Glyph Pallet. Using the Glyph Pallet puts all sorts of extra code in the file, which may or may not block other actions, like ligaturing.\n\nMore important is that you kern your minutes/seconds characters (aka prime/doubleprime) properly with all the numbers, and the period (check an ISBN format)\n\nI suppose less and less composition is being done by compositors & more & more by graphic designers. You know your market. But to take this another step back & let composition fall to the font designer seems fraught with peril.\n\n"
    },
    {
      "time": "30 May 2007 — 11:48am",
      "content": "Nick, remember the old adage that typography should serve the text? Let me propose a new one: digital typography should serve digital text. One of the implications of this is that the default glyph for a given character should not pretend to be a different character. Digital typography and text processing present us with a complex set of relationships between glyphs and characters, and we shouldn't make it any more complicated and we should avoid situations in which we basically use glyphs to lie about the identity of the underlying character.\n\nWe've fairly recently come out of a period in which designers became used to using encoding hacks to get at the glyph shapes they wanted (e.g. 'expert sets' for ligatures). These hacks were necessary because of the lack of a suitable mechanism for cleanly weaving display and text encoding. Now, with Unicode and OpenType, we have such a mechanism, but we also have a lot of possibilities for using glyph hacks to get at the glyph shapes of characters that might be less convenient to enter in text (despite the profusion of input methods, character and glyph pallettes, custom keyboard drivers, etc.). I understand the motivation, but I think it obscures exactly what we have gained in the Unicode/OpenType model -- a way to separate the sophisticated display of text from the encoding of text -- and that gain is best appreciated, and not needlessly muddied, if one observes some basic principles about character identity.\n\n"
    },
    {
      "time": "30 May 2007 — 12:56pm",
      "content": "Hello Charles, in ISBN I find numerals with hyphen mostly, do you mean kerning period with minutes/seconds, or period with numberals? Good tip to enter the Unicode number in InDesign, I was not aware that this is possible.\n\nHello Nick, to second what Miguel says: In very early versions of my fonts, 'ornm' substituted letters by arrows. Soon I understood why Adobe discontinued this practice, and remove this kind of substitution. Funny effect was that when I applied the new font versions on text originally set with previous ones, arrows turned into As & Bs again, and I didn't even recognize at first: letters in a stream of letters ... Same would happen if someone changes fonts that do have such fatures to fonts that don't. Such sudden changes may go unnoticed in our fast world.\n\n<cite>I agree with your criticism in principle, but in practice it’s very hard to find unusual characters in the glyph palette, especially in OT fonts with 1000s of characters.</cite>\n\nFinding a particular glyph in a large font will always be a 'challenge', but sorting glyphs nicely make help a little, like, a group for uppercase, smallcaps, lowercase, punctuation, numerals, numeral-related punctuation, etc.\n\n"
    },
    {
      "time": "30 May 2007 — 1:01pm",
      "content": "_sorting glyphs nicely_\n\nHow do you do that?  \nAny good models to follow?\n\n"
    },
    {
      "time": "30 May 2007 — 1:07pm",
      "content": "_Any good models to follow?_\n\nset your font to unicode mode and then go to gylphs \\> sort glyphs \\> by encoding. then switch to index mode and you can drag things around to where you'd like them to be. once you have everything set, you can save a custom encoding, next time you want to sort glyphs, set font to names mode, select your custom encoding and then go to glyphs \\> sort glyphs \\> by encoding. if there are any characters that are outside this encoding, you can again switch to index mode and move glyphs around as you like.\n\n"
    },
    {
      "time": "30 May 2007 — 1:25pm",
      "content": "And don't forget to switch the OpenType export option \"automatically reorder (or was it sort?) glyphs\" off.\n\nGood model -- hard to say. I think the order in the CT fonts is quite reasonable. Mine is a bit different. I am not aware of other examples and would be interested to see some.  \nBy the way, 'nice' sorting is even possible when using the AFDKO. Just sort the content of the GOAADB file as you like.\n\n"
    },
    {
      "time": "30 May 2007 — 1:51pm",
      "content": "Regarding glyph-sorting on the Glyph palette, I'll take this opportunity to point out that InDesign CS3 allows the glyphs to be sorted by Unicode\\*, in addition to the usual GID order.\n\nThe images below display the same font sorted by GID (top) and by Unicode (bottom). The new sorting method might be more intuitive for some people, as it puts together all the things that are somehow related with each other.\n\n\\* Unencoded glyphs, such as alternates and ligatures, are sorted as well.\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/IDCS3_GIDsort_4326.png)\n  \n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/IDCS3_UNIsort_5005.png)\n\n"
    },
    {
      "time": "30 May 2007 — 2:29pm",
      "content": "<cite>KL: Hello Charles, in ISBN I find numerals with hyphen mostly, do you mean kerning period with minutes/seconds, or period with numberals?</cite>\n\nKarsten, I think Charles meant to reference the LOC CIP listing, not ISBN. In the CIP data (formally: Library of Congress Cataloging-in-Publication Data), there is a catalog string that frequently uses a prime (very often mistakenly converted to an apostrophe by inattentive comps) and which may occur in conjunction with a period (although, off-hand, I can't think of an instance where I've encountered this).\n\nCharles, did I get that right?\n\n-- K.\n\n"
    },
    {
      "time": "30 May 2007 — 2:47pm",
      "content": "Miguel, if I want to have a category appear in the InD glyph palette \"show\" pull-down menu, named \"Mathematical symbols\", and another named \"Miscellaneous symbols\", how do I create that in the font?\n\n"
    },
    {
      "time": "30 May 2007 — 3:51pm",
      "content": "\\> _if I want to have a category appear in the InD glyph palette “show” pull-down menu, [...] how do I create that in the font?_\n\nYou can't. InDesign builds these categories, based on the font's character set and OpenType features included in it (top pic). However, in CS3 the user can make his/her own set(s) (bottom pic), which will appear on that drop-down menu.\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/gPalette_menu_4046.png)\n  \n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/gPalette_customSet_5306.png)\n\n"
    },
    {
      "time": "30 May 2007 — 4:23pm",
      "content": "KL -- <cite>I think Charles meant to reference the LOC CIP listing, not ISBN.</cite>\n\nI see. I had to search through a couple of books to finally find this in some IUP titles, indeed one of them showing an apostrophe, and in another the minute sign is followed by a period. Many thanks!\n\n"
    },
    {
      "time": "30 May 2007 — 6:17pm",
      "content": "Nick, regarding organising glyph sets in intuitive ways to assist users of glyph pallette entry:\n\nPretty much every project I do begins with the definition of a glyph set, usually in an Excel spreadsheet. This will contain at minimum a list of my development (human friendly) glyph names and corresponding Adobe Glyph List and uniXXXX form final names. I often include other information: if for instance I am working on a script for which I do not already have a FontLab .nam names-to-Unicode mapping, I will include encoding information in the spreadsheet. Obviously, after one has done a number of projects one has a collection of spreadsheets which can easily be manipulated to build new glyph sets. The listing of glyphs names can be copied into FontLab .enc files to create custom 'encodings', i.e. glyph sets in FontLab.\n\nUsing this approach, I group like-with-like glyphs in ways that, I hope, will be intuitive for locating and selecting from glyph pallettes.\n\n"
    },
    {
      "time": "30 May 2007 — 6:23pm",
      "content": "Kent, Karsten, you're right -- My mistake. For books published in the states, perhaps as a remnant of times when library sales were important to university preses, there was a block of copy furnished by the Library of Congress which was usually printed on the Copyright page. If it was in the book when printed, and in the same form as provided by LOC, the libraries could, in theory, get the books on the shelves faster.\n\nThe content of the copy was inviolate. The form was suppose to be followed as well, but Richard Eckersley (designer of <cite>The Telephone Book</cite>) started a bit of a revolution over that one, so now the form is often more in keeping with the rest of the interior design.\n\nAnyway, the number I was talking about, my wife informs me, is (she thinks) part of the Dewey Decimal system, and she further informs me that the prime seems to be absent from the newest material.\n\nEdit:\n\nFor an example: <cite>Retreat from Gettysburg</cite> by Kent Masterson Brown, University of North Carolina Press, ISBN 0-8078-2921-8 & \"funny little number\" 973.7'349--dc22 (& BTW, my Janson). I have seen the period \"interact\" with the prime, but don't have one to hand.  \n. . .\n\nYou can enter a Unicode character in ID2 running under Windows XC. As I sit at home typing on a Mac with an old keyboard, I'll probably make a mistake here too, but I believe if you hold down the shift+alt keys, and use the numeric key pad for any numbers, you'll get the Unicode character. There is a way using MS Word, too (again, Windows).\n\n"
    },
    {
      "time": "31 May 2007 — 12:03pm",
      "content": "i'd like to hear Adam Twardoch's take on this issue. Adam, are you out there?\n\n"
    },
    {
      "time": "31 May 2007 — 4:49pm",
      "content": "\\> ’ becomes “second”  \n\\> ” becomes “minute”\n\nYou mean: ’ becomes ″(which means \"second\") and ” becomes ′(which means \"minute\")???\n\nTo me, it makes no sense whatsoever. Why would one stroke be replaced by two strokes, and two strokes be replaced by one stroke?\n\nWell, I know, you made a typo and meant this to be the other way around, but it actually shows very well that your concept is flawed. It defeats WYSIWYG, it defeats Unicode.\n\nI definitely recommend AGAINST \"codepoint hacking\", i.e. assigning characters that have their own Unicode codepoints as glyph alternates of characters that have other Unicode codepoints, and are only mildly related by appearance.\n\nThe problem is that you invalidate the principle of \"text accessibility\". If you lie about the semantic level of text, i.e. you use a hack encoding to represent the litre symbol using the letter \"l\", then texts encoded electronically using Unicode lose their primary advantage, namely that the encoding of the text is \\*predictable\\*. Which means that one can cut-and-paste the text into a different software and he will get an approximation that will be as good as possible, even set in a different font. If the font is not available, the replacement will at least not be awkward.\n\nWhat if someone (a disabled person) uses a screen reading software? This software does not \"see\" the glyphs, it can only read the character encoding out loud. The screen reader software would read \"two ex three\" instead of \"two times three\", and \"two hyphen five\" instead of \"two minus five\".\n\nWhat if somebody is using search-and-replace in the \"naiive\" hope that what he sees as being a minute or second symbol actually is encoded as such? What if in half of the book typeset using your font the symbol has been typed in using the proper Unicode, and in the other half it was typed in using the hack Unicode with the feature applied? What if then, someone needs to do some text transformation, like global search-and-replace?\n\nI mean, theoretically, you could put code in your font such as\n\n`feature calt {\n  sub quotedbl' [A-Z a-z] by quotedblleft;\n  sub [A-Z a-z] quotedbl' by quotedblright;\n} calt;`\n\nbut this is just a nasty hack. The encoding starts to be font-dependant again, and we are back to times where you had to type in \"M\" to get a \"fi\" ligature.\n\nRemember old typewriters on which there was no key for digit \"1\" because the user was supposed to type in lowercase \"l\" instead? My mom had one like that. Well, why, it worked fine back then. These two glyphs look as much alike as ″ and ”.\n\nAdam\n\n"
    },
    {
      "time": "31 May 2007 — 8:36pm",
      "content": "So I take it you're no fan of Smarty Pants?\n\nOr similar \"curly-quote\" hacks in Quark and inDesign?\n\nIf those guys can get away with that kind of crap, why shouldn't I? :-)\n\n"
    },
    {
      "time": "31 May 2007 — 8:56pm",
      "content": "i understand that it's all about respecting the character input string, so we should just design fonts so as not to allow for lazy input? is a string of 1/8 really preferable to ⅛ when the latter is what is actually intended? I guess that's the thing though, is that we can't really guess what the user is intending, eh? we'd have a pretty good idea, however, if the user types 1/8, highlights the text, and then switches on the 'frac' feature. hmmm, but that seems just as much work as just selecting the appropriate glyph from the palette in the first place. i guess i just needed to post so as to talk myself into doing things the \"correct\" way. thanks for all your input everyone, a great discussion.\n\n"
    },
    {
      "time": "31 May 2007 — 10:19pm",
      "content": "Nick, when curly quotes are automatically substitued for ' and \" keystrokes in InDesign etc. this is a _character_ conversion. When you enter \"QUOTE\" what ends up in the text string are the curly quote characters U+201C and U+201D, not the keyboard entered straight quote U+0022. Essentially, the application providing users with an input method editor for typographical quote mark characters. This is a very different scenario from what you are proposing, which is a glyph conversion.\n\n"
    },
    {
      "time": "31 May 2007 — 10:30pm",
      "content": "Paul, fractions are an interesting case. A fairly small subset of common fractions happens to be encoded in Unicode as precomposed characters, e.g. ⅛; so far as I can gather, most of these encodings are for backwards compatibility. But fractions are by their nature generative and one very quickly exceeds that set of common fractions if one starts doing things with them: a fraction is, after all, a mathematical expression, a way of writing a division operation. So the logical way to encode fractions is as numerals separated by an operator: 1/8.\n\n"
    },
    {
      "time": "1 Jun 2007 — 3:06am",
      "content": "N.S. -- <cite>So I take it you’re no fan of Smarty Pants?</cite>  \n<cite>Or similar “curly-quote” hacks in Quark and inDesign?</cite>\n\nOn application level, yes, this is typing assistance.  \nOn font level, no. After all, fonts are databases providing applications with glyph outlines, and today may also include alterations of the outlines (substitution, repositioning).\n\nJ.H. -- <cite>But fractions are by their nature generative and one very quickly exceeds that set of common fractions if one starts doing things with them</cite>\n\nI like this description.  \nA similar case is fi/fl. If you design a sanserif typeface which does not need ligatures, you still add fi/fl for backward compatibility (MacOS Roman) but do not cover them in 'liga'. And hope nobody would select them from the glyph palette.\n\n(Were nice if a flag would allow type designers to <cite>hide</cite> certain glyphs from the palette.)\n\n"
    },
    {
      "time": "1 Jun 2007 — 4:59am",
      "content": "\"Smarty Pants\" are an extension of the keyboard driver -- assisting the user in typing in the correct Unicode. That's perfectly fine, because what ends up in the electronic text is Unicode-compatible, i.e. is what everybody expects.\n\nThe advantage of a standard is that it is a standard. Unicode has great chances to become THE standard to encode human writing (except perhaps for CJK languages that have some alternatives).\n\nThe WYSIWYG principle (What You See Is What You Get) these days is not only limited to \"what you see on screen is what you get on the printer\". It also means \"what you see on screen is what you get when you copy-paste or search\". This is why Adobe-compliant glyph names are important, and this is why adherence to the Unicode standard is important.\n\nAdam\n\n"
    },
    {
      "time": "1 Jun 2007 — 9:56am",
      "content": "OK, more devil's advocacy:\n\nStandards aren't the be-all and end-all. They're just a means to an end, and sometimes the means can screw up the end.\n\nI appreciate the breadth of John and Adam's concern for the integrity of the text across different media, but this may sacrifice initial typographic quality, and that seems absurd in, for instance a print piece where the text has little likelihood of being digitally searched, or reset.\n\n_the old adage that typography should serve the text?_\n\nI'm not sure how old that one is, although it does kick off Bringhurst's Style Guide (\"honour\" the text, actually). The older adage is serving the reader.\n\nAs Charles mentioned, knowing one's market (or audience) is important, and I wonder how many typographers who might be inclined to use the special characters I mentioned, would be comfortable entering unicode numbers? Not many, I would say -- they're going to use the glyph palette, now clutttered up with the wonders of massive Unicoded OT fonts. Sure, the filing systems described by Miguel will help, but in practice it's next to impossible to distinguish an apostrophe from a minute from an acute from a tonos.\n\nI am always amazed to come across typographic boo-boos in communications from blue-chip companies. Never mind that, in its printed missives to the design industry, Veer routinely abbreviates numbers with left-quotes, following the InDesign/SmartyPants practice. Good WYSIWYG, but poor typography.\n\nSurely the best way to encourage typographers to produce more sophisticated typography -- to serve the reading public, not the great god WYSIWYG -- is to make it really easy for them to, for instance, set the multiply sign, by simply applying the \"Stylistic Alternate\" feature to the character that's already in the text? (It would certainly have been easier for me to do something like that earlier in this thread, where I got minute and second muddled.)\n\nAnd despite Unicode's assertion that x and multiply are different characters, visually they really are stylistic alternates of the same character shape, and, in the context of any text where a faux Stylistic Alternate substitution would be made, there could never be any problem with meaning. Even in proper maths, because an italic font would be used for \"x\", precisely because of the interchangeability of \"x\" and \"multiply\".\n\nConsider this hypothetical scenario: an InDesigner is setting the captions for an art catalogue, and, for the artwork dimensions, wants to insert the correct multiply symbol in place of the manuscript's \"x\", throughout the text. Global substitution won't work, as that would change all \"x\"s, so \"find/change\" might be used. Except that the glyph palette doesn't connect to the \"change to\" field, and \"multiply\" isn't one of the characters available in the list of suitable substitutions (nice touch Adobe, BTW). So the InDesigner must do the job manually. I would be inclined to make the change once, then copy and paste. But how to make the first change from x to multiply? The glyph palette, of course, but if the font has the \"salt hack\" I'm proposing, that would be easier. And it would also work to convert the hash marks that measure the painting sizes in inches, into the proper inch mark (second).\n\nIn the most recent art catalogue I have (Contact photo festival), the designer has used all caps of a sans face (X really does look like multiply), and spelled out inches -- I would guess the difficulty of getting the proper characters/symbols has something to do with that decision.\n\n"
    },
    {
      "time": "1 Jun 2007 — 10:14am",
      "content": "Nick: _Consider this hypothetical scenario..._\n\nNot so hypothetical: this is the sort of thing I do on a regular basis. It's a pity that the glyph pallette doesn't accept focus to the find/replace dialogue, but this is easy enough to workaround. Make one manual substitution and then copy/paste the multiply symbol into the replace field of the dialogue and away you go.\n\nWhat would make it easier? If the find/replace dialogue had context fields! Then you could say, e.g. replace x with × when preceded and followed by any numeral. I think context fields should be standard in find/replace functions, and am amazed that no one seems to have thought of this.\n\nBut the basic point, Nick, is this: what you are complaining about is application functionality. And I don't think it makes any sense to try to solve application limitations in fonts. It is something that is very tempting to do sometimes, especially if it seems like there is an easy way to do it, but having spent the past decade working closely with application developers I've come to the conclusion that it is a really bad idea to second-guess them. Chances are that the way the application works will change -- hopefully improve -- and you are left with a quirky font that does odd things and a pile of poorly encoded text.\n\n"
    },
    {
      "time": "1 Jun 2007 — 12:41pm",
      "content": "_replace x with × when preceded and followed by any numeral_\n\nI had thought of doing that as Contextual Alternate, but it could screw up product code numbers. But yes, context fields in Find/Change, good idea!\n\n_what you are complaining about is application functionality._\n\nIt would be good if multiply and minus were on the keyboard too, like plus and equals.  \nAnd curly quotes.\n\n_I don’t think it makes any sense to try to solve application limitations in fonts._\n\nIt can be useful. The alternate glyphs in the case feature, for instance, solve an application problem (manual application of baseline shift) by automatically repositioning punctuation such as parentheses.\n\n\\*\\*\n\nHow about if instead of substituting \"Multiply\", applying Stylistic Alternate to \"x\" substitutes \"x.alt\" -- which has the same glyph as Multiply?\n\nThat way it doesn't mess with the Unicode.  \nAnd whereas the original manuscript was a \"lie\", in that it tried to pass off \"x\" for Multiply, the substitution of the correct glyph is true to the text's meaning.\n\n"
    },
    {
      "time": "1 Jun 2007 — 2:22pm",
      "content": "<cite>As Charles mentioned . . .</cite>\n\nJust to keep things clear, I think this a bad idea. You've had lots of good ones, but I don't feel this is one of them. If someone doesn't know how to set the needed character(s), they aren't a typesetter, let alone a compositor. No effort by a typefounder can change that, and will often get in the way of those who do know what they are doing.\n\nFWIW\n\n"
    },
    {
      "time": "1 Jun 2007 — 3:02pm",
      "content": "Nick: _but in practice it’s next to impossible to distinguish an apostrophe from a minute from an acute from a tonos._\n\nThat's what the Glyph palette's tooltip is for.\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/quoteright_ttip_4605.png)\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/singlequote_ttip_5058.png)\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/acute_ttip_5089.png)\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/prime_ttip_4004.png)\n\nJohn: _What would make it easier? If the find/replace dialogue had context fields! Then you could say, e.g. replace x with × when preceded and followed by any numeral._\n\nYou can do that with GREP, in InDesign CS3. The Find/Change expressions would be:  \nFind what: `(\\d)x(\\d)`  \nChange to: `$1×$2`\n\nNick: _How about if instead of substituting “Multiply”, applying Stylistic Alternate to “x” substitutes “x.alt” — which has the same glyph as Multiply?_\n\nThat is a \"better\" approach, but it does not solve anything. The underlying character will still be 'x', therefore any Search/Replace or screen reader software will always be fooled by that. They \"see\" characters, not glyphs.\n\n"
    },
    {
      "time": "1 Jun 2007 — 4:32pm",
      "content": "Miguel: I don't get the Name line -- but then, I'm using CS (not CS2 or CS3) -- is that a later addition?\n\n_That is a “better” approach, but it does not solve anything._\n\nI think it does for print, although the screen reader will always be problematic.  \nBTW how does the screen reader handle \"second\"? -- it's going to get it wrong if it's supposed to be inches or degree of arc! Those should have separate Unicode points...\n\nAdam: _What if in half of the book typeset using your font the symbol has been typed in using the proper Unicode, and in the other half it was typed in using the hack Unicode with the feature applied?_\n\nI see what you mean. Or if a typographer has already been through the text and changed all the \"x\"s to faux \"multiply\", using my suggested Stylistic Alternate feature, and then the font is changed to one without such a feature, it would be a pain to have to do it all over again with the correct Unicode procedure.\n\nSo I'm conviced it's a \\*bad idea\\* and won't do it in any fonts.\n\nCharles: _If someone doesn’t know how to set the needed character(s), they aren’t a typesetter, let alone a compositor._\n\nI'm floating the idea of making things more convenient for people who do know, and more accessible for those on the cusp. And those still using CS who aren't getting the TypeTip names.\n\nYou know, I posted this same thread in the general section and got one response (plus Adam). I just get the feeling that we're so into all these OpenType complexities, ramping up the characters and features in fonts, while the OT menu remains buried and unheralded in CS and Quark (not to mention Microsoft) -- and meanwhile the vast majority of users think OpenType is just for fancy script ligatures.\n\nWe need more Ilenes spreading the news!  \n [http://www.fonts.com/AboutFonts/Articles/fyti/06-01-05.htm](http://web.archive.org/web/20150130163915/http:/www.fonts.com/AboutFonts/Articles/fyti/06-01-05.htm \"http://www.fonts.com/AboutFonts/Articles/fyti/06-01-05.htm\")\n\n"
    },
    {
      "time": "1 Jun 2007 — 5:13pm",
      "content": "\\> _I don’t get the Name line — but then, I’m using CS (not CS2 or CS3) — is that a later addition?_\n\nNot sure when it got added, but it's definitely in CS2. It got improved in CS3, where the \"Name:\" entry was added. The tooltip is also displayed for alternate glyphs and ligatures. In these cases, the Unicode displayed is the one of the base character(s).\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/liga_ttip_4415.png)\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/smcp_ttip_6559.png)\n\n ![](http://web.archive.org/web/20150130163915im_/http:/typophile.com/files/ornm_ttip_4713.png)\n\n\\> _BTW how does the screen reader handle “second”? — it’s going to get it wrong if it’s supposed to be inches or degree of arc! Those should have separate Unicode points…_\n\nI'm not sure how the reader will make the distinction between minutes and feet, or between seconds and inches, given that there's only one codepoint for each. Unicode calls them 'prime' and 'double prime'. [http://www.unicode.org/charts/PDF/U2000.pdf](http://web.archive.org/web/20150130163915/http:/www.unicode.org/charts/PDF/U2000.pdf \"http://www.unicode.org/charts/PDF/U2000.pdf\")\n\n"
    },
    {
      "time": "2 Jun 2007 — 10:26am",
      "content": "\\> X really does look like multiply\n\nIn some fonts X really looks like multiply, and in some fonts l really looks like 1. In some fonts, rn looks like m. So what? Would you put this code into your font:\n\n`feature liga {\nsub r n by m;\n} liga;`\n\n? Makes no sense whatsoever.\n\nCharacter encoding must bear necessary semantic differentiation, because a lot of software depends on it. For example, in Unicode, some characters have the property of being \"letters\" while some don’t, some have the property of having uppercase or lowercase variants, they belong to different writing systems etc.\n\nAll this information gets screwed up if you start making glyph alternates the way you suggest it. This interfers with various mechanisms such as spellchecking, hyphenation, the way OpenType features are being applied to a string or not.\n\nThe solutions you propose are OK for fonts that you produce on a completely custom basis, for very controlled, closed environment, where you maintain contact with the client in future. But never for retail fonts, because despite what you may write in your user’s manual for the font, people will use the font their way, may use it on systems and applications that you never heard that they existed, and, above all, may use them \\*according\\* to the standards that you choose to ignore.\n\nThis reminds me of the situation when people started producing Cyrillic or CE fonts in Type 1 format in the early 1990s. They simply placed the Cyrillic glyphs, or the accented Polish or Czech glyphs, in the slots of Western glyphs (using the fact that one code position in the Western codepage stood for some particular character in the Cyrillic or CE codepage). They didn’t care to set up appropriate glyph names and encoding flags. Those fonts worked fine in QuarkXPress 3 and 4, and in PageMaker, and in Illustrator 6, and in Photoshop 4.\n\nBut these fonts are STILL in circulation. 15 years later, people moved to a Unicode-based system. When they open old Quark documents in Quark 7, the automatic conversion from codepage-based encodings to Unicode fails because Quark \"thinks\" the document is set in French and not in Russian, so the user ends up with character spaghetti. Also, these fonts are virtually unusable in Quark 7 or InDesign. And the users curse the font vendor.\n\nOn the other hand, there are Type 1 fonts from other font vendors that were created by the rules. They worked just exactly as fine in the old apps, \\*and\\* 15 years later they still work, and the documents created with them also do work.\n\nIf you make the fonts \"your way\", they may work fine in InDesign CS3 but perhaps will stop working properly in InDesign CS5, because Adobe would have introduced a mathematical typesetting engine that correctly enters and formats math equations, but this engine might rely on arithmetic operators being encoded \\*properly\\*. So if the user opens an old document typeset in your font that says \"5×6\", the math engine will recognize this as an equation and add some extra spacing around the × sign accordingly, but if the text in the document looks like  \n\"5×6\" but actually _says_ \"5x6\", then the math engine may reformat it to \"5_x_6\" because it thinks the \"x\" is a variable name.\n\nEtc. etc.\n\nThe advantage of using standards is that they offer much larger future stability. I.e. even if the standards change or get replaced, there is a great chance that the people who develop the new or the modified standards in future will also develop _standard_ ways of migrating the old structures to the new ones. If you deliberately **break** today's standards, it's almost certain that this will **break** the future migration, either of the fonts or of the documents that the font was used in. In any way, your users will be penalized -- either today (those who use your font on platforms that you didn’t bother testing, or using them in a context that you didn’t envision or that you deemed \"unimportant\") or tomorrow.\n\nI personally would always warn users from purchasing hack-encoded fonts. The graphic qualities of such fonts may be fine but the functional side of the design is broken. I'm not interested in wearing a wrist watch that looks great but every now and then randomly stops working for 15 seconds or jumps ahead one minute. The same is with fonts.\n\nA.\n\n"
    },
    {
      "time": "2 Jun 2007 — 10:55am",
      "content": "This sort of substitution really should be a setting option in a layout program, but yes, never scripted within the font its self. A little tick on the style bar to indicate you're setting math, and even then \\* and / keystrokes should be substituted with multiply and divide (already standard for keying in those math functions), respectively, to avoid ambiguity btweeen multiply and _x_.\n\n"
    },
    {
      "time": "2 Jun 2007 — 11:16am",
      "content": "Adam, I already capitulated.\n\nRegarding backwards compatability, just follow the money.  \nYou can open a Quark 3 document on an Intel Mac, but only if you buy Quark 7. Don't need new fonts though, thanks to the stellar philanthropy of type foundries!\n\nDon't you think that's a bit of a double standard?\n\nAfter all, Quark, InDesign and Word have incorporated faux features (bogus weight, italicization, scaling, small caps) since day one.  \nTo paraphrase; the functional qualities of such software may be fine, but the typographic side of the design is broken.\n\nJohn states that fonts shouldn't attempt to fix application shortcomings with hacks, but the converse is exactly what apps do with faux features.\n\n"
    },
    {
      "time": "2 Jun 2007 — 1:32pm",
      "content": "Nick: _It can be useful. The alternate glyphs in the case feature, for instance, solve an application problem (manual application of baseline shift) by automatically repositioning punctuation such as parentheses._\n\nThat assumes that the effect of case feature substitutions is always equivalent to a baseline shift, but this is not so. case feature substitutions may involve changes to the form of glyphs as well as to their vertical positioning, not to mention spacing. In fonts in which the default numeral forms are oldstyle, it makes sense to put mappings to lining numerals in the case feature. So the case feature is not simply doing in the font what could be done at the application level: it is things that are glyph centric and need to be controlled at the font level.\n\n_John states that fonts shouldn’t attempt to fix application shortcomings with hacks, but the converse is exactly what apps do with faux features._\n\nAnd I likewise think that they should not or, at least, should not do so automatically. If, when the user clicked the italic button in Word, for example, a dialogue popped up saying\n\n'The font family you are using does not include an italic font. Do you want Word to slant the regular font to fake an italic?'\n\nthat would be preferable to automatic slanting.\n\n"
    },
    {
      "time": "2 Jun 2007 — 10:03pm",
      "content": "_That assumes that the effect of case feature substitutions is always equivalent to a baseline shift..._\n\nThat wasn't my assumption, although I did express myself sloppily. Although I didn't say \"some of\" the alternate glyphs, I didn't mean \\*all\\* of the substitutions are equivalent to baseline shifts.\n\nI was just giving an example of how a font can solve a layout application difficulty.\n\nAnd really, isn't that how OpenType features work? The substitution coding is in the font.  \nIt would in theory be possible to just name the glyphs in a font, and have the app do the substitutions. For instance, with \"one.numr\", \"fraction\", and \"nine.dnom\" as font glyphs, an application fraction-maker could construct 11/99.\n\nI would imagine that might be how Adam's putative CS5 math engine would work.\n\n"
    },
    {
      "time": "2 Jun 2007 — 10:03pm",
      "content": "Anyway, thanks for your comments, everybody.  \nI'm glad the extra \"superior\" glyphs passed muster -- are there any others that could be added, other than these footnote symbols?\n\n"
    },
    {
      "time": "3 Jun 2007 — 9:47am",
      "content": "BTW, the faux italicization really comes from the \\*extremely\\* early days of computing, where you had bitmap fonts, very few fonts, low-resolution printers etc. (where you wouldn’t even actually tell the roman from the italic, easily). Remember, those were the days where fonts came on floppy disk and using three different fonts on a page might overload your printer’s memory. And the expression \"electronic documents\" probably didn’t exist (neither did the PDF format).\n\nWe’re 20 years into future now. Yes, some apps still maintain the faux italic for backward-compatibility reasons. But there is no need or reason to come up with NEW solutions that still follow this old-style way of thinking.\n\nA.\n\n"
    },
    {
      "time": "3 Jun 2007 — 11:24am",
      "content": "_...they should not or, at least, should not do so automatically._\n\nThe same is true of \"SmartyPants\", and \"Typographic Quotes\", which is a default of InDesign, isn't it?\n\n_Yes, some apps still maintain the faux italic for backward-compatibility reasons._\n\nI don't think that's the main reason. It's because application engineers think their application can fill in the gaps in a font family, and they believe it's a genuine service to the user to do so. For instance, InDesign offers users small caps of any font, even those with no true small caps.\n\n_no need or reason to come up with NEW solutions that still follow this old-style way of thinking._\n\nThe need for Smarty-Pants: typographers hate seeing hash mark quotes and apostrophes, and if Smarty can fix that, they don't mind the hack, even if it screws up abbreviations like '07.\n\nBut as I said, your (and others') arguments against \\*lying\\* Stylistic Alternatives have convinced me that it would be impractical to include them in my fonts. Thank-you!\n\n"
    },
    {
      "time": "4 Jul 2007 — 9:19am",
      "content": "this is really a bit of a sticky wicket, isn't it? everyone seems to be in agreement that OT features should not be used for character conversion, but even the most recently released fonts by Adobe substitute scedilla with scommaaccent in the 'locl' feature. if we were following this non-conversion rule strictly, scedilla would be replaced by scedilla.locl (a clone of scommaaccent), right? So, is there just a bit of wiggle room with this rule, or should it be followed absolutely?\n\n"
    },
    {
      "time": "4 Jul 2007 — 9:08pm",
      "content": "Paul,\n\nthe Scedilla-\\>Scommaaccent case is indeed special. The proper Unicode codepoint to be used with Romanian is that of Scommaaccent (U+0218). Unfortunately, some old Unicode implementations use U+015E (Scedilla) in the Romanian locale. This means that the Romanian text can be represented in two different ways, \"old\" (using Scedilla) and \"new\" (using Scommaaccent). The \"locl\" OpenType replacement helps migrate the electronic text from the old to the new encoding. In this very case, the font helps fix a particular isolated encoding problem.\n\nAlso, the Scedilla-\\>Scommaaccent replacement in \"locl\" for Romanian has become a widely accepted practice now. Both Unicode and OpenType work on that very principle: if something becomes widely accepted practice, it can be codified. So if you manage to convince enough people to follow a particular method, you may be lucky with your stuff getting \"standardized\".\n\nA.\n\n"
    },
    {
      "time": "13 Jul 2007 — 11:10am",
      "content": "back to this topic...  \nwould it be advisable to have some type of feature where for character composition (besides ccmp) so that the user would know that if this feature is enabled certain characters are converted easily to symbols? For example, many PC users are used to the automatic replacement of **1/2** to **½** and of **(C)** to **©**. Would it be so bad to have a symbol composition feature (symb, hypothetically) that could build on these standardized (by Microsoft) practices to make symbols easily accessible via simple key combinations instead of having to hunt through a glyph palette?\n\n"
    },
    {
      "time": "9 Aug 2007 — 4:04pm",
      "content": "Paul,\n\na conversion of (C) to © on the glyph level is rather bad because it breaks Unicode. Any OpenType features that break Unicode should be avoided unless there is a really strong argument to do it anyway.\n\nAdam\n\n"
    },
    {
      "time": "9 Aug 2007 — 4:45pm",
      "content": "_For example, many PC users are used to the automatic replacement of 1/2 to ½ and of (C) to ©._\n\nBut these are character-level substitutions performed by the application. So what ends up in the text string when (C) is coverted to © is © not (C). If this substitution were performed at the glyph level, then the text string would remain (C), which is not the copyright symbol.\n\n"
    },
    {
      "time": "10 Aug 2007 — 2:58pm",
      "content": "Right. This is a particularly important issue for the copyright symbol, because the c-in-parens has no legal relevance. It has to either be the copyright symbol or the word \"copyright.\"\n\nDisclaimer: At least, that's what I've heard from lawyers. I'm not a lawyer myself and of course you should consult an actual lawyer for impartial legal advice.\n\nRegards,\n\nT\n\n"
    },
    {
      "time": "14 Sep 2007 — 3:29am",
      "content": "...in addition to which, I often type (c) to mean (c), as in lists. When I want a copyright symbol, I know how to get it. Word used to substitute one for the other with its AutoCorrect settings, until I got fed up with it and switched it off. I wouldn't want that ‘feature' built into the font. Not that Word knows about OpenType features, but you get my drift...\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_  \nEver since I chose to block pop-ups, my toaster's stopped working.\n\n"
    },
    {
      "time": "3 Oct 2008 — 3:26am",
      "content": "back to this, Miguel said:  \n_Many of Adobe’s early Pro fonts have similar kinds of substitutions (e.g. in Warnock Pro the ornaments are alternates of lowercase Latin letters), but this is not really a good practice\\*. These and other substitutions (like sub [a A] by ordfeminine;) were implemented in the font to make its usage convenient from the user’s POV, but they’re not good because they replace character(s) by other character(s)._\n\nwhere do these replacements actually occur? i'm curious. i'm still trying to understand the workings behind the scenes. for example, if you have a font that substitutes f f i (u0066 u0066 u0069) by ffi (uFB03), what problems will arise? what will happen if you name the substituted glyph f\\_f\\_i and still assign the unicode point (uFB03)?\n\n"
    },
    {
      "time": "3 Oct 2008 — 4:40am",
      "content": "\\> _where do these replacements actually occur? i’m curious. i’m still trying to understand the workings behind the scenes. for example, if you have a font that substitutes f f i (u0066 u0066 u0069) by ffi (uFB03), what problems will arise?_\n\nThere are no actual replacements in e.g. InDesign. The underlying characters will remain the same when you apply the features; only the displayed glyphs will change. The issues may occur latter when, let's say, you generate a PDF file, send it to someone, and that person tries to retrieve the text from the PDF (or perform a search). If the PDF has a ToUnicode table, the text might come out with U+FB03, instead the original U+0066 U+0066 U+0069. If there's no ToUnicode table in the PDF, the glyph name will be parsed. According to [this list](http://web.archive.org/web/20150130163915/http:/partners.adobe.com/public/developer/en/opentype/glyphlist.txt) the glyph name ffi will correspond to character U+FB03, and according to [these rules](http://web.archive.org/web/20150130163915/http:/www.adobe.com/devnet/opentype/archives/glyph.html) the glyph name f\\_f\\_i will be mapped to the characters f, f and i. [This page](http://web.archive.org/web/20150130163915/http:/www.adobe.com/devnet/opentype/archives/glyphnamelimits.html) explains where and why glyph names are used.\n\n\\> _what will happen if you name the substituted glyph f\\_f\\_i and still assign the unicode point (uFB03)?_\n\nI think it will depend on how the glyph was inserted, which app generated the PDF and which app reads it and accesses the PDF contents. Ideally, the glyph f\\_f\\_i should be unencoded, and a glyph duplicate of it — named uniFB03 (or ffi) — should be the one to carry the encoding. But what you describe is not at all bad. That's actually what we do in our fonts. The reasoning being that we favor the ligature aspect — therefore the glyph name f\\_f\\_i and not ffi —, but at the same time we don't want people to get notdefs if the text happens to contain the character U+FB03 — therefore we assign the code point.\n\n"
    },
    {
      "time": "28 Apr 2014 — 6:36am",
      "content": "This thread is quite dated, but I’d like to comment on it nevertheless, because two important aspects are missing from all answers that opposed Nick Shinn’s idea (the second part of it that is).\n\n**1.** Not all text can be controlled by the same person or entity who chooses the font.  \nThis applies most prominently to the Web where the reader can ultimately choose the font and a multitude of stakeholders can suggest one (or actually more than one).\n\nSite owners, their designers, editors and authors should enforce the correct character which will have the correct glyph as long as one of the typefaces used supports it, but browser vendors and users may use techniques to correct typographic nonos. This could be done by scripts, e.g. Greasemonkey, that replace _characters_, but why not let fonts replace _glyphs_ instead?\n\n**2.** Not all of the suggestion are the same.  \nThere are several legacy characters in Unicode that fulfill multiple functions with a unified glyph. I strongly believe it’s fine for smart fonts to make these characters adapt their glyphs to the context when an appropriate one can be chosen without ambiguity.  \nThis applies to U+0027 `'`, U+0022 `\"` and U+002D `-` most prominently, but maybe , U+0060 ``` and perhaps U+00B4 `´` or U+002A `*` as well.\n\n    @DIGIT = [zero one two three four five six seven eight nine]; \n    # also .*num\n    feature salt {\n    \n    lookup prime {\n      # second or inch and minute or foot\n      # context: following a digit without a space in between\n      # U+0027 ' quotesingle ➞ U+2032/02B9 ʹ prime / primemod / minute\n      # U+0022 \" quotedbl ➞ U+2033/02BA ʺ doubleprime / doubleprimemod / second\n      sub @DIGIT [quotesingle quotedbl]' by [prime doubleprime]; \n    } prime;\n    \n    lookup apostrophe {\n      # apostrophe, also Hawaiian okina etc.\n      # context: between letters\n      # U+0027 ' quotesingle ➞ U+2019/02BC ’ quoteright / apostrophemod\n      sub @LETTER quotesingle' @LETTER by quoteright; \n      # An apostrophe may appear at the start or end of a word,\n      # but it then can not be distinguished from a single quote mark reliably,\n      # because looking for a matching one can only be done for very simple cases in OT.\n      # In English, both look the same at the right-hand side anyway\n      # and one could add lexical rules for words where initial apostrophe is common, e.g. ’n’, ’tis.\n    } apostrophe;\n    \n    lookup quotemark {\n      # default, also English\n      # context open: between a space or certain punctuation and a letter or certain punctuation.\n      # U+0027 ' quotesingle ➞ U+2018 ‘ quoteleft\n      # U+0022 \" quotedbl ➞ U+201C “ quotedblleft\n      # U+0060 ` grave ➞ U+2018 ‘ quoteleft\n      sub @WORDBOUNDARY [quotesingle quotedbl grave]' [@LETTER @DIGIT @INITIALPUNCT] \n       by [quoteleft quotedblleft quoteleft];\n      # context close: between a letter or certain punctuation and a space or certain punctuation\n      # U+0027 ' quotesingle ➞ U+2019 ’ quoteright\n      # U+0022 \" quotedbl ➞ U+201D ʺ quotedblright\n      # U+00B4 ´ acute ➞ U+2019 ’ quoteright\n      sub [@LETTER @DIGIT @FINALPUNCT] [quotesingle quotedbl acute]' @WORDBOUNDARY \n       by [quoteright quotedblright quoteright];\n      # to do: add localized variants\n    } quotemark;\n    \n    lookup mathoperator {\n      # U+002A * ➞ U+00D7 × multiply\n      # U+002D - ➞ U+2212 − minus\n      sub @DIGIT [asterisk hyphen]' by [multiply minus];\n      sub @DIGIT @SPACE [asterisk hyphen]' by [multiply minus];\n      sub [asterisk hyphen]' @DIGIT by [multiply minus];\n      sub [asterisk hyphen]' @SPACE @DIGIT by [multiply minus];\n    } mathoperator;\n    \n    lookup dash {\n      # U+002D - ➞ U+2013 – endash or U+2014 — emdash\n      ignore sub hyphen hyphen' hyphen' hyphen';\n      sub hyphen' hyphen' hyphen' by emdash;\n      sub @SPACE' hyphen' hyphen' @SPACE' by emdash;\n      sub hyphen' hyphen' by endash;\n      sub @SPACE hyphen' @SPACE by endash;\n    } dash;\n    \n    @SIPREFIX = [Y Z E P T G M K k H h D d m micro mu n p f a z y];# without deka\n    lookup litre {\n      # l ➞ U+2113 ℓ litre\n      # context: after a digit, perhaps separated by a space, \n      # perhaps preceded by an SI prefix (1 or 2 letters), not followed by a letter. \n      # only lowercase, because ‘L’ is already an unambiguous variant\n      ignore sub l' @LETTER;\n      sub @DIGIT l' by litre;\n      sub @DIGIT @SPACE l' by litre;\n      sub @DIGIT @SIPREFIX l' by litre;\n      sub @DIGIT @SPACE @SIPREFIX l' by litre;\n      sub @DIGIT d [a k] l' by litre;\n      sub @DIGIT @SPACE d [a k] l' by litre;\n    } litre;\n    \n    } salt;\n\nUnlike the asterisk, the glyph for the lowercase letter `x` must not be replaced by the one for times `×`, because neither is the cross a normal glyph variant (like the script el) nor is the letter a generic/unified character.  \nAt least the first of these reasons also applies to the suggested fist replacement U+003E `>` ➞ U+261E ☞.\n\nI’m not sure, `salt` is the best feature for this, though.\n\n"
    },
    {
      "time": "30 Apr 2014 — 8:00am",
      "content": "Crissov, I think you should avoid text correction on the font level. What may work in English may not work in other languages. There are also many exceptions where the font substitutions fail: while 1939–1945 is an interval with en-dash, 1939-1945 might be a product with a hyphen; if you substitute hyphen with en-dash, how would user correct it then? OpenType cannot solve such issues.\n\nIn my design studio, we've created an extensive and language sensitive list of find-change entries. We use it as a script for InDesign (based on the default FindChangeByList.jsx script) and we run it whenever we import a text in InDesign. It is 1000× smarter than OpenType features, it includes several very complex and contextual solutions.\n\nI think it is pretty easy to develop such find-replace tool for texts on websites as well. There is one similar plugin for WordPress for instance wp-typography ( [http://kingdesk.com/projects/wp-typography/](http://web.archive.org/web/20150130163915/http:/kingdesk.com/projects/wp-typography/ \"http://kingdesk.com/projects/wp-typography/\")), maybe there are now newer ones available.\n\n"
    }
  ]
}
